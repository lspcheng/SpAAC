---
title: "n1b"
output: html_document
---

# Preamble
## Packages
```{r setup}
# Load libraries and custom functions
if (file.exists("project_functions.R")){
  source("project_functions.R")
  
} else { # try one directory up
  source("../project_functions.R")
}

# Text Analysis
library(countrycode)
library(maps)
library(tidytext)

# Plots
library(hrbrthemes)

# Functions
quick_summarize <- function(df, col, na.rm=FALSE){
  col = enquo(col)
  df %>%  summarize(across(!!col, list(median= ~ median(.x, na.rm=na.rm), mean= ~ mean(.x, na.rm=na.rm),
                                       sd= ~ sd(.x, na.rm=na.rm), min= ~ min(.x, na.rm=na.rm), 
                                       max= ~ max(.x, na.rm=na.rm))))
}

```

## Pipeline Structure
```{r}
# Fill in file structure info (e.g. using getwd())
NAME <- 'n1b' ## Name of the R file (w/o file extension!)
PHASE <- 'P0-norming' ## Name of the project phase (if relevant)
PROJECT <- 'SpAAC' ## Name of project
```

```{r}
# Get project directory path & subfolder status from working dir
PROJECT_DIR <- str_extract(getwd(), paste0("^(.*?)",PROJECT,"/"))

if (basename(getwd()) != PHASE) {SUBFOLDER <- basename(getwd())} else {SUBFOLDER <- NA}

# Get pipeline path names
if (dir.exists(file.path(PROJECT_DIR, '04-analysis', '02-pipeline'))){
  if (is.na(SUBFOLDER)){
    pipeline <- file.path(PROJECT_DIR, '04-analysis', '02-pipeline', PHASE, NAME)
  } else {
    pipeline <- file.path(PROJECT_DIR, '04-analysis', '02-pipeline', PHASE, SUBFOLDER, NAME)
  }
} else {
  pipeline <- file.path('.', 'pipeline', PHASE, NAME)
}

# Create pipeline folders
if (!dir.exists(pipeline)) {
  dir.create(pipeline, recursive=TRUE)
  for (folder in c('out', 'store', 'temp')){
    dir.create(file.path(pipeline, folder))
  }
}
```

```{r}
# Basic reference paths
stim_data_path <- file.path(PROJECT_DIR, '02-materials', '02-stimuli', PHASE) 
ext_data_path <- file.path(PROJECT_DIR, '03-data', '01-external', PHASE) 
int_data_path <- file.path(PROJECT_DIR, '03-data', '02-internal', PHASE) 
manual_analysis_path <- file.path(PROJECT_DIR, '04-analysis', '03-manual', PHASE) # 001-code / 003-manual
```


# .
# Set-up

## Review Comments

On Qualtrics "Results" Tab (i.e., not the Data & Analysis tab), view the comments about the task to get a sense of what participants thought and if there are things to change for the next batch.

Can also do a quick review of the demographics.

## Export Files

**(1) Prolific**
On the Prolific study page, click on "Download Demographic data".

**(2) Qualtrics: Screener**
From Qualtrics Data & Analysis page, export the screener data file.

Select these basic options:
* Download all fields
* Use choice text

Select these advanced options:
* Split multi-value fields into columns

NOTE: Don't include the -99 because I'll be able to easily exclude the NAs instead.

**(3) Qualtrics: Main Survey**
From Qualtrics Data & Analysis page, export the data file.

Select these basic options:
* Download all fields
* Use numeric values (first) AND choice text (second)

Select these advanced options:
* Recode seen but unanswered multi-value fields as 0
* Recode seen but unanswered questions as -99
* Split multi-value fields into columns
* Export viewing order data for randomized surveys

NOTE: Must include the -99 because it will result in -99 for pages where nothing was selected, which I can then convert to 0 (else, it will be NA, which I couldn't separate from unseen NAs, i.e., unpresented blocks).

### (*) Set Filenames
Pilot set (n=8) data files.
Main set (n=...) data files
Final set (n=10 + 3) data files

```{r}
# Set File paths
RUN <- "1-1_pilot"

pilot_prolific <- list.files(file.path(int_data_path, NAME, RUN),  pattern="prolific_export", full.names = TRUE)
pilot_screener <- list.files(file.path(int_data_path, NAME, RUN),  pattern="+Screener", full.names = TRUE)
pilot_data_num <- list.files(file.path(int_data_path, NAME, RUN),  pattern="_num", full.names = TRUE) 
pilot_data_text <- list.files(file.path(int_data_path, NAME, RUN),  pattern="_text", full.names = TRUE) 

RUN <- "1-2_main"
main_prolific <- list.files(file.path(int_data_path, NAME, RUN),  pattern="prolific_export", full.names = TRUE)
# main_prolific_1 <- file.path(int_data_path, NAME, RUN, "prolific_export_647674eff562724a9f3b8394.csv") # n1b — 2
# main_prolific_2 <- file.path(int_data_path, NAME, RUN, "prolific_export_647674ebfd3b2b5494abcf01.csv") # n1b — 3
# main_prolific_3 <- file.path(int_data_path, NAME, RUN, "prolific_export_6478d1379cc5fe472f276074.csv") # n1b — 4
# main_prolific_4 <- file.path(int_data_path, NAME, RUN, "prolific_export_647de66d14bd4b43fe5c7f15.csv") # n1b — 4
main_screener <- list.files(file.path(int_data_path, NAME, RUN),  pattern="+Screener", full.names = TRUE) 
main_data_num <-  list.files(file.path(int_data_path, NAME, RUN),  pattern="_num", full.names = TRUE)
main_data_text <- list.files(file.path(int_data_path, NAME, RUN),  pattern="_text", full.names = TRUE)

# # File paths for: RUN <- "1-3_final"
# final_prolific <- list.files(file.path(int_data_path, NAME, RUN),  pattern="prolific_export", full.names = TRUE)
# final_screener <- list.files(file.path(int_data_path, NAME, RUN),  pattern="+Screener", full.names = TRUE) 
# final_data_num <-  list.files(file.path(int_data_path, NAME, RUN),  pattern="_num", full.names = TRUE)
# final_data_text <- list.files(file.path(int_data_path, NAME, RUN),  pattern="_text", full.names = TRUE)

# Get Current File paths
RUN_LIST <- c("pilot", "main", "final") # "test"
CURRENT_RUN <-  "main" # RUN_LIST[2] # To get last value: RUN_LIST[length(RUN_LIST)]

if (CURRENT_RUN == "pilot"){
  current_prolific <- pilot_prolific
  current_screener <- pilot_screener
  current_data_num <- pilot_data_num
  current_data_text <- pilot_data_text
} else if (CURRENT_RUN == "main" ) {
  current_prolific <- main_prolific
  current_screener <- main_screener
  current_data_num <- main_data_num
  current_data_text <- main_data_text  
} else if (CURRENT_RUN == "final") {
  current_prolific <- final_prolific
  current_screener <- final_screener
  current_data_num <- final_data_num
  current_data_text <- final_data_text  
}

print(CURRENT_RUN)
print(current_prolific)
print(current_screener)
print(current_data_num)
print(current_data_text)
```

## (*T) Check Test Data 
Using simulated (pre-pilot, test) data, check data labels and prep code for cleaning data (columns, etc). During this iterative process, go back to Qualtrics survey and update codes and labels where necessary to ensure clean output data.
Pre-pilot set data files.
```{r}
# RUN <- "0-1_initialtest"
# 
# test_data_num <- file.path(int_data_path, NAME, RUN, "Visual+Style+Impressions_May+29,+2023_09.45_num.csv")
# test_data_text <- file.path(int_data_path, NAME, RUN, "Visual+Style+Impressions_May+29,+2023_09.45_text.csv")
```

Some of this code adapted for wrangling participant data.
```{r}
# # NOTE: Unfinished data doesn't appear in the export file until X days later. That's why the data may seem to change if I export new data later.
# 
# # Use numeric data for main task
# n1b_data <- read_csv(test_data_num)  %>% 
#   filter(Finished!=0) %>%
#   select(-StartDate:-UserLanguage) %>% # Remove metadata columns (first several). See raw data for columns Progress, Duration, Finished, RecordedDate
#   slice(-2)  # Remove unnecessary question header rows (1,2)
# n1b_data
# 
# # Use text data for subject data
# n1b_data_text <- read_csv(test_data_text)  %>% 
#   filter(Finished!="False") %>%
#   select(-StartDate:-UserLanguage) %>% # Remove metadata columns (first several)
#   slice(-2) # Remove unnecessary question header rows (1,2)
# n1b_data_text
```

```{r}
# # Get randomized images order list per subject
# # Check for even distribution
# n1b_data %>%
#   select(contains("Q2.5")) %>% select(contains("DO")) %>% slice(-1) %>%
#   mutate(subj=1:n(), .before=1) %>% # Add temp subj number for simulated data
#   pivot_longer(cols=2:last_col(), names_to=c(NA, NA, "Photo_Number"), names_sep="_", values_to = "DO") %>% type.convert() %>%
#   arrange(subj, DO) %>% drop_na(DO) %>%
#   pivot_wider(subj, names_from = DO, names_prefix = "Trial", values_from = Photo_Number)
#   
```

```{r}
# # Get informative question labels
# q_labels <- 
#   n1b_data %>%
#   select(`1_Q3.1_1`:`30_Q3.12`) %>% select(-contains("DO")) %>% # select only looped trials, excl, DisplayOrder
#      slice(1) %>%
#   pivot_longer(cols=everything(), names_to=c("Photo_Number", "Question_Number", "Question_Part_Number", NA), names_sep="_", values_to = "q_label") %>%
#   # Since number of dashes and <> location aren't consistent, need to remove everything between < > and extra -
#   mutate(q_label = gsub("<.*>", "", q_label)) %>%
#   mutate(q_label = gsub("^(\\s*-\\s*)", "", q_label)) %>%
# mutate(q_label = gsub("(-\\s+.*\\s+-)", "-", q_label)) %>%
#   separate(q_label, into= c("Question", "Question_Part"), sep = "-", extra="merge")
# q_labels 
```

```{r}
# # Get question data + merge with informative question labels
# test_data <- n1b_data %>%
#   select(`1_Q3.1_1`:`30_Q3.12`) %>% select(-contains("DO")) %>% # select only looped trials, excl, DisplayOrder
#   slice(-1) %>% # remove second header
#   mutate(subj=1:n(), .before=1) %>% # Add temp subj number for simulated data
#   pivot_longer(cols=2:last_col(), names_to=c("Photo_Number", "Question_Number", "Question_Part_Number", NA), names_sep="_", values_to = "responses") %>%
#   full_join(q_labels, .)
# test_data
```
```{r}
# # Check question labels for all questions (even those not shown to participants, are NA)
# test_data %>%  group_by(subj) %>%  count() #870
# test_data %>%  group_by(subj, Photo_Number) %>%  count() # 29
# test_data %>%  group_by(subj, Photo_Number, Question) %>%  count() 
# test_data %>%  group_by(subj, Photo_Number, Question, Question_Part) %>%  count()
```
```{r}
# # Get only data shown to participants (i.e., drop NA)
# test_data_clean <- test_data %>%
#   drop_na(responses)
# 
# # Check n of total questions by subj and photo
# # For rough check (not very meaningful)
# test_data_clean %>% group_by(subj) %>%  count()
# test_data_clean %>%  group_by(subj, Photo_Number) %>% count() %>% type_convert() %>% arrange(subj, Photo_Number) # 29
# test_data_clean %>% group_by(Photo_Number)%>% count() %>% type_convert() %>% arrange(Photo_Number)
# 
# # Check n of trials by subj and photo 
# # For confirming even presentation (randomization) of photos
# # Total presented/answered photos (end goal: 600)
# test_data_clean %>% select(subj, Photo_Number) %>% distinct() %>% count()
# # Total presented/answered photos per participant (process/end goal: 10 per subject)
# test_data_clean %>% select(subj, Photo_Number) %>% distinct() %>% count(subj)
# # Total presented/answered participants per photo (end goal: 20 per photo)
# test_data_clean %>% select(subj, Photo_Number) %>% distinct() %>% count(Photo_Number) %>% type_convert() %>% arrange(Photo_Number)

```




# Pre-Process Screener Data

## (*) Read, Wrangle

```{r}
# Read in Prolific "Demographic data" from the study page
n1b_prolific_demo <- 
  plyr::ldply(pilot_prolific, read_csv, na= c("", "NA", "DATA_EXPIRED")) %>% mutate(Run=RUN_LIST[1]) %>%
  full_join(plyr::ldply(main_prolific, read_csv, na= c("", "NA", "DATA_EXPIRED")) %>% mutate(Run=RUN_LIST[2])) %>%
  # full_join(read_csv(final_prolific) %>% mutate(Run=RUN_LIST[3])) %>%
  mutate(Time_in_min=`Time taken`/60, .after=`Time taken`)  
n1b_prolific_demo
```

```{r}
n1b_screener_data <- read_csv(current_screener) %>%
# Remove metadata columns (first several)
  select(-StartDate:-UserLanguage) %>%
  # Remove uneccessary question header rows (1,2)
  slice(-1:-2) %>%
  unite("Ethnicity", Ethnicity_9:Ethnicity_14, sep=",", na.rm=TRUE, remove=FALSE) %>%
relocate(Device, .after = Ethnicity) %>%
  rename(`Participant id` = Prolific_ID)

  #TEMP: Remove returned/non-consent participants, bad participants, outliers while checking, before deleting
# n1b_screener_data <- n1b_screener_data %>% filter(!(PROLIFIC_PID%in% c("62a15df1dd6fa394ea04f063"))) <- REPLACE if needed
  
n1b_screener_data 
# View(screener_data)
```

```{r}
# Compare screener to prolific demographic
n1b_screener_v_prolific <-
  n1b_screener_data %>% full_join(n1b_prolific_demo, by="Participant id")  %>% 
  select(
    Run,
    `Participant id`,
    Time_in_min,
    State_Born, `U.s state/territory of birth`,
    State_Current, `Current u.s state of residence`,
    Ethnicity_screen=Ethnicity.x, Ethnicity_prolific=Ethnicity.y, `Ethnicity simplified`,
    Device
    #, .after=`Participant id`
  ) 
# Show full data
n1b_screener_v_prolific

# Check and Remove Run==NA rows, where no Prolific data (i.e., generally, returned participants)
n1b_screener_v_prolific_NA <- n1b_screener_v_prolific %>% filter(is.na(Run))
n1b_screener_v_prolific_NA

n1b_screener_v_prolific <- n1b_screener_v_prolific %>%  drop_na(Run)
n1b_screener_v_prolific
```


## Check, Summarize
Check the prescreener data for consistency with the main data.
### (*C) Sample Check
#### Duplicates
```{r}
# Check for duplicated participant id issues
n1b_screener_v_prolific %>% count(`Participant id`) %>% arrange(desc(n))
```

#### Time Taken
```{r}
#Time_in_min
n1b_screener_v_prolific %>% 
  # filter(Run == CURRENT_RUN) %>%
  summarize(mean_Time=mean(Time_in_min, na.rm=TRUE), median_Time=median(Time_in_min, na.rm=TRUE),
            min_Time=min(Time_in_min, na.rm=TRUE), max_Time=max(Time_in_min, na.rm=TRUE),
            sd_Time=sd(Time_in_min, na.rm=TRUE)) %>%
  mutate(low_cutoff=min_Time-sd_Time*3, high_cutoff=max_Time+sd_Time*3)
```
#### Region
```{r}
# Sample Counts: Region
n1b_screener_v_prolific %>%  count(`Current u.s state of residence`, `U.s state/territory of birth`)
n1b_screener_v_prolific %>%  count(State_Current,State_Born)
```
#### Ethnicity
```{r}
# Sample Counts: Ethnicity
n1b_screener_v_prolific %>%  count(Ethnicity_prolific)
n1b_screener_v_prolific %>%  count(Ethnicity_screen)
```

#### Device
```{r}
# Sample Counts: Device
n1b_screener_v_prolific %>%  count(Device)
```

####  (*C) By-Participant Check
```{r}
participant_list <- n1b_screener_v_prolific %>% filter(Run==CURRENT_RUN) %>%  pull(`Participant id`)
participant_list
```

```{r}
current_participant <- "64136da866ff27f7bf98cfe0" #participant_list[1] #"5f7d4a2c5db79d21c7d07240"

n1b_screener_data %>%  filter(PROLIFIC_PID == current_participant) #Prolific_ID

n1b_screener_v_prolific %>%  filter(`Participant id` == current_participant) #Prolific_ID
```



# Pre-Process Main Data
## Read
Read in exported data, and check what it looks like.

NOTE: Remove data from subjects who did not complete the study ("returned" on Prolific) or have been identified to be outliers, not following instructions, not fulfilling my participant requirements, etc. Outliers are identified in a later section below (Outlier Check), while participant requirements are checked in the data from the questionnaire.

```{r}
# Use numeric data for main task
  # NOTE: Unfinished data doesn't appear in the export file until X days later. That's why the data may seem to change if I export new data later.

n1b_data <- read_csv(current_data_num)  %>% 
  filter(Finished!=0) %>%
  # Remove metadata columns (first several). See raw data for columns Progress, Duration, Finished, RecordedDate + question header rows (1,2) + function cols
  select(-StartDate:-UserLanguage) %>% 
  slice(-2) %>% select(-Q1.2,-starts_with("Ex")) 
  # Remove returned/non-consent participants, bad participants, outliers.
n1b_data %>% colnames()


# Use text data for subject data
n1b_data_text <- read_csv(current_data_text)  %>% 
  # NOTE: Unfinished data doesn't appear in the export file until X days later. That's why the data may seem to change if I export new data later.
  filter(Finished!="False") %>%
  # Remove metadata columns (first several) + question header rows (1,2)
  select(-StartDate:-UserLanguage) %>% 
  slice(-2)  %>% select(-Q1.2,-starts_with("Ex")) 
n1b_data_text
```

```{r}
n1b_data %>% pull(PROLIFIC_PID)
```
Next, read in image/filename decoding information that was originally constructed in Google sheets (SpAAC: Visual Stimuli) and downloaded as CSV.
```{r}
# Read in image decoding file
n1b_codes <- read.csv(file.path(stim_data_path, NAME, "02-records","SpAAC Visual Stimuli - N1b_Stims.csv")) %>%
  mutate(Photo_Number = seq(1:n()), .before="Critical.Filler")
n1b_codes
```

## Wrangle


### Subject Data
Before moving on, check the Task short-answer reflections and Demographic data + Randomization data.
```{r}
# Extract relevant Info from 
n1b_subj <- n1b_data_text %>%
  # Get Part 1 end and Demographics
  select('Q4.3':'VERSION') %>% 
  janitor::row_to_names(1, remove_rows_above = FALSE) %>% # Uses first row as colnames
  type_convert()
n1b_subj
```

#### Conditions
Process randomization/condition information. Check that randomization is working (e.g., displaying randomly, evenly). Includes version and photo numbers by participant and trial.
```{r}
n1b_subj_cond <- n1b_subj %>% 
  select(PROLIFIC_PID, VERSION) %>%
  full_join(
    # Get randomized images order list per subject
    n1b_data %>%
    select(PROLIFIC_PID, contains("Q2.5_DO")) %>% slice(-1) %>%
    pivot_longer(cols=2:last_col(), names_to=c(NA, NA, "Photo_Number"),
                 names_sep="_", values_to = "DO") %>% type.convert() %>%
      arrange(PROLIFIC_PID, DO) %>% drop_na(DO) %>%
      pivot_wider(PROLIFIC_PID, names_from = DO, names_prefix = "Trial",
                  values_from = Photo_Number)
  )
n1b_subj_cond 

## UNCOMMENT to check a participant
# n1b_subj_cond %>%  filter(PROLIFIC_PID=="596fc4717008ef000109703d")
```


Process Part 1 End responses about the task.
```{r}
# View
(n1b_subj_p1 <- n1b_subj %>% select(PROLIFIC_PID, WhatTaskAbout:TaskNotice))
```
Process Part 2 responses about the personal demographics.
```{r}
n1b_subj_p2 <- n1b_subj %>% select(PROLIFIC_PID, Age:VERSION) %>%
  # Convert -99 to NAs
  mutate(across(where(is.numeric), ~na_if(., -99))) %>%
  mutate(across(where(is.character), ~na_if(., "-99"))) %>%
  rename_with(., ~ gsub(" - Selected Choice", "", .x, fixed=TRUE)) %>%
  # Clean text responses
  mutate(Gender=tolower(Gender), Ethnicity=tolower(Ethnicity)) %>%
  #mutate(Gender=gsub(" ", "", Gender), Ethnicity=gsub("-", " ", Ethnicity)) %>%
  mutate(Gender=mgsub(Gender, c("^female|^woman", "^male|^man"), c("f", "m"), fixed=FALSE)) %>%
  mutate(Ethnicity=mgsub(Ethnicity, c("han ", "(mandarin)", "and honk-kongese"), c("", "", "; hongkongese"), fixed=TRUE)) %>%
  mutate(Ethnicity=mgsub(Ethnicity, c("(\\s|\\-)american", "/"), c("", ", "), fixed=FALSE)) # remove american
n1b_subj_p2
```

#### Summary
#### (*R) Sample Check
```{r}
# Total Participant entries
n1b_subj_p2 %>% count()

# Total Participants per condition
n1b_subj_p2 %>% add_count(name="total_n") %>% count(VERSION, total_n, name="group_n") %>% 
  mutate(prop = round(group_n/total_n,2))
```
##### Age
```{r}
# Age
n1b_subj_p2 %>% quick_summarize(Age)
```
```{r}
# Visualize Age
n1b_subj_p2 %>%
  ggplot() +  gg_theme() +
  geom_histogram(aes(x=Age), binwidth=1, alpha=0.7)
```


##### Gender
```{r}
# Gender overall
n1b_subj_p2 %>% add_count(name="total_n") %>% count(Gender, GenderCat, total_n, name="group_n") %>% 
  mutate(prop = round(group_n/total_n,2))
```

```{r}
# Gender by Age, colored
n1b_subj_p2 %>%
  ggplot() +  gg_theme() +
  geom_histogram(aes(x=Age, fill=GenderCat), binwidth=1, alpha=0.7)

# Visualize Gender
n1b_subj_p2 %>%
  ggplot() +
  gg_theme() +
  geom_bar(aes(x=GenderCat, fill=GenderCat), alpha=0.7) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
```

##### Ethnicity
```{r}
# EthnicityCat
n1b_subj_p2 %>%
  count(EthnicityCat) %>%
  arrange(-n)

# Specific Ethnicity
n1b_subj_p2 %>%
  count(Ethnicity, EthnicityCat) %>%
  arrange(-n)

# Other: Ethnicity by Gender 
n1b_subj_p2 %>%
  count(Ethnicity, GenderCat) %>%
  arrange(-n) %>%
  pivot_wider(., Ethnicity, names_from = "GenderCat", values_from = "n") %>%
  mutate(across(where(is.integer), ~ coalesce(.x, 0L))) %>%
  group_by(Ethnicity) %>% mutate(total=sum(Woman, Man), .after=Ethnicity)
```
```{r}
# Visualize Ethnicity
# By Gender
n1b_subj_p2 %>%
  group_by(Ethnicity) %>% mutate(Ethnicity_n=n()) %>% ungroup() %>%
  ggplot() +  gg_theme() +
  geom_bar(aes(x=reorder(Ethnicity, -Ethnicity_n), fill=GenderCat, linetype=EthnicityCat), alpha=0.7) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  labs(x="Ethnicity")

# With Ethnicity Cat
n1b_subj_p2 %>%
  group_by(Ethnicity) %>% mutate(Ethnicity_n=n()) %>% ungroup() %>%
  ggplot() +  gg_theme() +
  geom_bar(aes(x=reorder(Ethnicity, -Ethnicity_n), fill=EthnicityCat), alpha=0.7) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  labs(x="Ethnicity") %>% scale_fill_viridis(discrete=TRUE)
```


##### Location
```{r}
# # Check location info for summary statement
n1b_subj_p2_loc <-
  n1b_subj_p2 %>%
  select(PROLIFIC_PID, starts_with("Location")) %>%
  mutate(across(everything(), as.character)) %>%
  rename_with(., ~ gsub(".*(\\d)", "\\1", .x)) %>% # Remove everything before the first digit, but keep the digit (via the parenthesis and \\1)
  pivot_longer(cols = 2:last_col(), names_to = c("Loc", "Info"), names_sep=" - ", values_to = "Response") %>%
  pivot_wider(id_cols=PROLIFIC_PID:Loc, names_from = Info, values_from = Response) 
# n1b_subj_p2_loc # <- UNCOMMENT to view
```

##### Network
```{r}
n1b_subj_p2_network <- n1b_subj_p2 %>% select(PROLIFIC_PID, contains("Community") | contains("Contacts")) %>%
  mutate(across(everything(), as.character)) %>%
  pivot_longer(cols = 2:last_col(), names_to = c("Question", "Ethnicity"), names_sep=" - ", values_to = "Response") %>%
  filter(!is.na(Response)) %>% filter(Response!="0") %>%
  pivot_wider(id_cols=c(PROLIFIC_PID, Ethnicity), names_from = Question, values_from = Response, values_fill='0') %>% type_convert()
n1b_subj_p2_network <- n1b_subj_p2_network %>%
  full_join(n1b_subj_p2_network %>% group_by(PROLIFIC_PID) %>% summarize(total_CloseContacts = sum(CloseContacts, na.rm=TRUE))
  ) %>%
  mutate(prop_CloseContactsLocal = CloseContactsLocal/100,
        prop_CloseContacts = round(CloseContacts/total_CloseContacts, 2),
         prop_RegularContacts = RegularContacts/100,
         prop_BroaderCommunity = BroaderCommunity/100) %>%
  select(PROLIFIC_PID:Ethnicity, n_CloseContacts=CloseContacts, prop_CloseContactsLocal, prop_CloseContacts, prop_RegularContacts, prop_BroaderCommunity) %>%
  mutate(across(where(is.numeric), ~ ifelse(is.na(.x), 0, .x)))
n1b_subj_p2_network

summary(n1b_subj_p2_network)
```

```{r}
# View per Ethnicity data summary
# Q1 -- selections for SocialCommunityNetwork (i.e., all undropped rows)
n1b_subj_p2_network %>% count(Ethnicity)
n1b_subj_p2_network %>% add_count(PROLIFIC_PID) %>% count(PROLIFIC_PID,n,  Ethnicity) %>% select(-nn)

# Q3 -- CloseContactsLocal
n1b_subj_p2_network %>% group_by(Ethnicity) %>% quick_summarize(prop_CloseContactsLocal, na.rm=TRUE)

# Q2 -- CloseContacts
n1b_subj_p2_network %>% group_by(Ethnicity) %>% quick_summarize(prop_CloseContacts, na.rm=TRUE)

# Q4 -- Regular Contacts
n1b_subj_p2_network %>% group_by(Ethnicity) %>% quick_summarize(prop_RegularContacts, na.rm=TRUE)

# Q5 -- BroaderCommunity
n1b_subj_p2_network %>% group_by(Ethnicity) %>% quick_summarize(prop_BroaderCommunity, na.rm=TRUE)
```

```{r}
# Get Asian-specific experience
# Filter to only East and Southeast Asian experience
n1b_subj_p2_asian <- n1b_subj_p2_network %>% filter(Ethnicity=="East Asian"|Ethnicity=="Southeast Asian") %>%
  mutate(n_CloseContactsLocal = n_CloseContacts*prop_CloseContactsLocal, .after=n_CloseContacts)
n1b_subj_p2_asian

# Total N for Asian (absolute)
n1b_subj_p2_asian %>% group_by(PROLIFIC_PID) %>% summarize(n_CloseContacts = sum(n_CloseContacts), n_CloseContactsLocal = round(sum(n_CloseContactsLocal)))

# Total prop for Asian (relative)
n1b_asian_network <- n1b_subj_p2_asian %>%
  # Get local prop of total, not just of subcategory/row
  mutate(prop_LocalCloseContacts = prop_CloseContactsLocal * prop_CloseContacts, .after=prop_CloseContactsLocal) %>%
  # Get total props across both east and southeast asian = "Asian"
  group_by(PROLIFIC_PID) %>% summarize(prop_AsianLocalCC = sum (prop_LocalCloseContacts), prop_AsianCC = sum(prop_CloseContacts), prop_AsianRC = sum(prop_RegularContacts), prop_AsianBC = sum(prop_BroaderCommunity)) %>%
  # Get unweighted total Asian estimate
  mutate(prop_Asian = (prop_AsianCC + prop_AsianRC + prop_AsianBC)/3)
n1b_asian_network
```

```{r}
# Get sample summary
n1b_asian_network %>% summarize(across(where(is.numeric), mean))

# # Q3 -- CloseContactsLocal
n1b_asian_network  %>% quick_summarize(prop_AsianLocalCC, na.rm=TRUE)
n1b_asian_network  %>% quick_summarize(prop_AsianCC, na.rm=TRUE)
n1b_asian_network  %>% quick_summarize(prop_AsianRC, na.rm=TRUE)
n1b_asian_network  %>% quick_summarize(prop_AsianBC, na.rm=TRUE)
n1b_asian_network  %>% quick_summarize(prop_Asian, na.rm=TRUE)

# Visualize (WIP)
# n1b_asian_network %>% pivot_longer() %>%
#   ggplot(aes(x=prop_AsianCC)) + geom_boxplot()
```
```{r}
n1b_asian_network %>%
  ggplot(aes(x=prop_Asian, y=prop_AsianCC, size=prop_AsianRC)) + gg_theme() +
  geom_point(alpha=0.2) 

n1b_asian_network %>%
  ggplot(aes(x=prop_AsianCC, y=prop_AsianRC, size=prop_AsianBC)) + gg_theme() +
  geom_point(alpha=0.2) + 
  labs(title="Asian Network", x="Close Contacts", y="Regular Contacts", size="Broader Community")

n1b_asian_network %>%
  ggplot(aes(x=prop_AsianBC, y=prop_AsianRC, size=prop_AsianCC)) + gg_theme() +
  geom_point(alpha=0.2) + 
  labs(title="Asian Network", x="Broader Community", y="Regular Contacts", size="Close Contacts")

n1b_asian_network %>%
  ggplot(aes(x=prop_AsianBC, y=prop_AsianCC, size=prop_AsianRC)) + gg_theme() +
  geom_point(alpha=0.2) + 
  labs(title="Asian Network", x="Broader Community", y="Close Contacts", size="Regular Contacts") 
```
Notes: 
- Most people seem to have a minimum proportion of Asian Close Contacts at 0.25 (one exception of 0).
- All correlate somewhat, Regular and Close seem most related? (Regular and Broader somewhat)
- A number of people at all Asian contacts across the board
- There seems to be a bit of a split between 50% or more Asian in the Broader community linked to more Asian regular Contacts and Close Contacts — i.e., almost nobody has under 50% Close/Regular Contacts when large Community 

- Possibly can use CloseContacts as an estimate of interactive exposure + RegularContacts OR BroaderCommunity for a more general estimate, if needed. Otherwise, one estimate would probably be enough

#### (*C) By-Participant Check
```{r}
participant_list <- n1b_screener_v_prolific %>% filter(Run==CURRENT_RUN) %>%  pull(`Participant id`)
participant_list
```
Run the following to screen participant data. Mainly, check that they fit the demographic criteria.

Pilot = 1:8
Main1 = 8:
```{r}
# Print all in range
for (i in 1:length(participant_list)){
  current_participant <- participant_list[i]
    
  # UNCOMMENT TO view subj data by subject
  # print(n1b_subj_p2 %>% filter(PROLIFIC_PID == current_participant))
  
  # View locations by subject
  print(
    n1b_subj_p2_loc %>%  filter(PROLIFIC_PID == current_participant) %>%
    filter(!(is.na(`from Age`)))
  )
}
```

```{r}
# Check single participant
current_participant <- "5b5955e7f2333f00013176b2" # OR e.g. participant_list[3]

# View subj data by subject
n1b_subj_p2 %>% filter(PROLIFIC_PID == current_participant)

# View locations by subject
n1b_subj_p2_loc %>%  filter(PROLIFIC_PID == current_participant) %>%
  filter(!(is.na(`from Age`)))
```
<!-- UPDATE THIS STATEMENT AS NEEDED:  -->
<!-- All participants were born in, spent the majority of their childhood in, and were living in California* at the time. -->
All participants were born in and/or grew up in and were living in California* at the time (based on the screener).
```{r}
# Notes on Participant Locations (if needed).

# 63d007388da4ef5b301762f9 -- declined to answer
# 6365408f2a24d08a0f2a66ae -- declined to answer
# 5e6cade3d92ffb26677dbd84 -- born in NY but moved to CA at ~6 months old
# 6277fd1a3a086f8af7867fa0 -- born in CA, moved around a bit, mainly growing up in georgia (age 6-18), now back in CA (18-19)
# 5b5955e7f2333f00013176b2 -- born in Shanghai, grew up in CA since age 2
# 5b117f18c61ce0000126305a -- born and grew up in Virginia from 0-12; but 12-30 live in San Diego
```


### Main Data

Next, get just the response data with informative question labels. To be able to extract info from not only header but also first row, isolate the first row via slice(). Then, wrangle to get all the relevant info.

After that, isolate the actual data via slice (2nd row onwards) then pivot_longer and merge in by-question information (note: the original pivot_longer should match on both datatables). Drop unseen/unshown questions/blocks (i.e. NAs). Then, merge in the image codes!

NOTE: Can drop Question_Number and Question_Part_Number if not useful as shorthand.

```{r}
# Get informative question labels from header and first row

n1b_response_info <-  n1b_data %>%
  select(`1_Q3.1_1`:`30_Q3.12`) %>% select(-contains("DO")) %>% # select only looped trials, excl, DisplayOrder
     slice(1) %>%
  pivot_longer(cols=everything(), names_to=c("Photo_Number", "Question_Number", "Question_Part_Number", NA), names_sep="_", values_to = "q_label") %>%
  # Since number of dashes and <> location aren't consistent, need to remove everything between < > and extra - rather than just separate() or str_extract()
  mutate(q_label = gsub("<.*>", "", q_label)) %>%
  mutate(q_label = gsub("^(\\s*-\\s*)", "", q_label)) %>%
mutate(q_label = gsub("(-\\s+.*\\s+-)", "-", q_label)) %>%
  separate(q_label, into= c("Question", "Question_Part"), sep = "-", extra="merge")
n1b_response_info

# Get question data + merge with informative question labels
n1b_responses <- n1b_data %>%
  select(PROLIFIC_PID, `1_Q3.1_1`:`30_Q3.12`) %>% select(-contains("DO")) %>% # select only looped trials, excl, DisplayOrder
  slice(-1) %>% # remove second header
  pivot_longer(cols=2:last_col(), names_to=c("Photo_Number", "Question_Number", "Question_Part_Number", NA), names_sep="_", values_to = "Response") %>%
  full_join(n1b_response_info, .) %>% relocate(PROLIFIC_PID) %>%
  
  mutate(Response=ifelse(Response==-99,NA,Response)) %>% drop_na(Response) %>% # Drop unpresented + unanswered qs
  mutate(Response = case_when(Question=="Recognize" & Response=="2" ~ "No",
                              Question=="Recognize" & Response=="1" ~ "Yes",
                              TRUE ~ Response)) %>%
  type_convert() %>% # Auto-Convert number character columns to numeric
  full_join(., n1b_codes) %>% select(-Code) %>%
  mutate(across(where(is.character), as.factor))
n1b_responses
summary(n1b_responses)
# View(n1b_responses)
save(n1b_responses, file=file.path(pipeline, "temp", "n1b_responses"))

```

#### Summary
Make a targeted dataframe with just the useful/relevant columns for easier viewing.
```{r}
# Select relevant columns only.
n1b_responses_selected <- n1b_responses %>%
  select(PROLIFIC_PID, Question, Question_Part, Condition, Image_Cat, Image, Photo_Number, Response) %>%
  mutate(across(where(is.character), as.factor)) %>%
  mutate(Response = case_when(Question=="Recognize" & Response=="2" ~ "No",
                              Question=="Recognize" & Response=="1" ~ "Yes",
                              TRUE ~ Response)) 
n1b_responses_selected
# View(n1b_responses_selected)
save(n1b_responses_selected, file=file.path(pipeline, "store", "n1b_responses_selected.RData"))
```

#### Check
Check and explore the data here.

Error check, i.e., manually view strange things in the data to fix them above
```{r}
# E.g., filter(is.na(Image)) ; filter(Response==-99)
# n1b_responses %>% filter(Question == "Ratings")
# 
# n1b_responses_selected %>% filter(Question == "Ratings")  %>% count(PROLIFIC_PID) %>% arrange(n)
# 
# # View one participant/slice
# n1b_responses_selected %>%  filter(PROLIFIC_PID=="6366fd2bd9ad6300b4cbc7df") %>% filter(Question=="Ratings") %>% count(Photo_Number, Image)
  # View()
```

```{r}
# Notes:
# PROLIFIC_PID=="6366fd2bd9ad6300b4cbc7df --- one missing rating for photo 15 / AAW-47 on Attractiveness (no way to fix, but noted — that's why total Ratings is -1; e.g. rather than 3360 it's 3359)
```


##### (*R) By-Sample Check

Sanity Check: Check the number of by-subject and by-photo counts. Does randomization seem to be working alright?
Can reset the randomization counts based on these numbers, so that started and unfinished surveys don't affect the final counts.
```{r}
# Check n of trials by subj and photo 
# For confirming even presentation (randomization) of photos

# Total presented/answered photos (end goal: 600)
n1b_responses %>% select(PROLIFIC_PID, Photo_Number) %>% distinct() %>% count()
# Total presented/answered photos per participant (process/end goal: 10 per subject)
n1b_responses %>% select(PROLIFIC_PID, Photo_Number) %>% distinct() %>% count(PROLIFIC_PID)
# Total presented/answered participants per photo (end goal: 20 per photo)
n1b_responses %>% select(PROLIFIC_PID, Photo_Number) %>% distinct() %>% count(Photo_Number) %>% arrange(Photo_Number)

```
```{r}
# Conditions, sample sizes, sample means, time taken, outliers(?)
# summary(n1b_responses)
summary(n1b_responses_selected)
```

##### (*C) By-Participant Check
Get the participants list.
```{r}
participant_list <- n1b_screener_v_prolific %>% filter(Run==CURRENT_RUN) %>%  pull(`Participant id`)
participant_list
length(participant_list)
```

Run the following iteratively to screen participant data. Mainly, check that they seemed to answer the questions in good faith. If not, add notes below. If it's all fine, then accept their submission.
```{r}
current_participant <- "5b117f18c61ce0000126305a" #participant_list[10] # 

current_responses <- n1b_responses %>% 
  select(PROLIFIC_PID, Question, Question_Part, Image, Response) %>% 
  filter(PROLIFIC_PID == current_participant) %>%
  mutate(Response = case_when(Question=="Recognize" & Response=="2" ~ "No",
                              Question=="Recognize" & Response=="1" ~ "Yes",
                              TRUE ~ Response)) 

current_responses %>% filter(Question=="Impressions") %>% pivot_wider(id_cols = c(PROLIFIC_PID, Image), names_from = Question_Part, values_from = Response)

# Non-numeric responses
current_responses %>% filter(Question=="Age") %>%
  filter(Response!=0) %>% select(PROLIFIC_PID, Image, Question_Part, Response)  %>%
  pivot_wider(id_cols = c(PROLIFIC_PID, Image), names_from = Question_Part, values_from = Response)

current_responses %>% filter(Question=="Occupation") %>% select(-contains("Question_Part"))
current_responses %>% filter(Question=="Activities") %>% select(-contains("Question_Part"))
current_responses %>% filter(Question=="GrewUp") %>% select(-contains("Question_Part"))
current_responses %>% filter(Question=="Ethnicity") %>% select(-contains("Question_Part"))
current_responses %>% filter(Question=="Speech") %>% select(-contains("Question_Part"))
current_responses %>% filter(Question=="Recognize") %>% select(-contains("Question_Part"))

# Rating responses
current_ratings <- current_responses %>% filter(Question=="Ratings") %>% select(-"Question") %>% select(-PROLIFIC_PID) %>%
  mutate(Scale=str_extract(Question_Part, "(?<=:).+(?=$)")) %>% type_convert()

current_ratings %>%
  filter(Question_Part == str_match(Question_Part, ".*American.*|.*Native.*")) %>% 
  select(Image, Scale, Response) %>% pivot_wider(id_cols = Image, names_from = Scale, values_from = Response)

current_ratings %>% summary()
current_ratings %>% group_by(Image) %>% quick_summarize(Response, na.rm=TRUE)
current_ratings %>% group_by(Scale) %>% quick_summarize(Response, na.rm=TRUE)
current_ratings %>% quick_summarize(Response, na.rm=TRUE)

print(current_participant)
```

```{r}
# Response Patterns Review Notes

```

