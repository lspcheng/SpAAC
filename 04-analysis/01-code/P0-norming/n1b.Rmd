---
title: "n1b"
output: html_document
---

# Preamble
## Packages
```{r setup}
# Load libraries and custom functions
if (file.exists("project_functions.R")){
  source("project_functions.R")
  
} else { # try one directory up
  source("../project_functions.R")
}

# Location
library(countrycode)
library(maps)

# Plots
library(hrbrthemes)
```

## Pipeline Structure
```{r}
# Fill in file structure info (e.g. using getwd())
NAME <- 'n1b' ## Name of the R file (w/o file extension!)
PHASE <- 'P0-norming' ## Name of the project phase (if relevant)
PROJECT <- 'SpAAC' ## Name of project
```

```{r}
# Get project directory path & subfolder status from working dir
PROJECT_DIR <- str_extract(getwd(), paste0("^(.*?)",PROJECT,"/"))

if (basename(getwd()) != PHASE) {SUBFOLDER <- basename(getwd())} else {SUBFOLDER <- NA}

# Get pipeline path names
if (dir.exists(file.path(PROJECT_DIR, '04-analysis', '02-pipeline'))){
  if (is.na(SUBFOLDER)){
    pipeline <- file.path(PROJECT_DIR, '04-analysis', '02-pipeline', PHASE, NAME)
  } else {
    pipeline <- file.path(PROJECT_DIR, '04-analysis', '02-pipeline', PHASE, SUBFOLDER, NAME)
  }
} else {
  pipeline <- file.path('.', 'pipeline', PHASE, NAME)
}

# Create pipeline folders
if (!dir.exists(pipeline)) {
  dir.create(pipeline, recursive=TRUE)
  for (folder in c('out', 'store', 'temp')){
    dir.create(file.path(pipeline, folder))
  }
}
```

```{r}
# Basic reference paths
stim_data_path <- file.path(PROJECT_DIR, '02-materials', '02-stimuli', PHASE) 
ext_data_path <- file.path(PROJECT_DIR, '03-data', '01-external', PHASE) 
int_data_path <- file.path(PROJECT_DIR, '03-data', '02-internal', PHASE) 
manual_analysis_path <- file.path(PROJECT_DIR, '04-analysis', '03-manual', PHASE) # 001-code / 003-manual
```


# .
# Set-up

## Review Comments

On Qualtrics "Results" Tab (i.e., not the Data & Analysis tab), view the comments about the task to get a sense of what participants thought and if there are things to change for the next batch.

Can also do a quick review of the demographics.

## Export Files

**(1) Prolific**
On the Prolific study page, click on "Download Demographic data".

**(2) Qualtrics: Screener**
From Qualtrics Data & Analysis page, export the screener data file.

Select these basic options:
* Download all fields
* Use choice text

Select these advanced options:
* Split multi-value fields into columns

NOTE: Don't include the -99 because I'll be able to easily exclude the NAs instead.

**(3) Qualtrics: Main Survey**
From Qualtrics Data & Analysis page, export the data file.

Select these basic options:
* Download all fields
* Use numeric values (first) AND choice text (second)

Select these advanced options:
* Recode seen but unanswered multi-value fields as 0
* Recode seen but unanswered questions as -99
* Split multi-value fields into columns
* Export viewing order data for randomized surveys

NOTE: Must include the -99 because it will result in -99 for pages where nothing was selected, which I can then convert to 0 (else, it will be NA, which I couldn't separate from unseen NAs, i.e., unpresented blocks).

### (*T) Filenames
Pre-pilot set data files.
```{r}
CURRENT_RUN <- "0-1_initialtest"

# test_prolific <- file.path(int_data_path, NAME, CURRENT_RUN, "prolific_export_63867500bc6d482404655d65.csv")
# test_screener <- file.path(int_data_path, NAME, CURRENT_RUN, "Visual+Style+Selection +Screener_December+14,+2022_18.58.csv")
test_data_num <- file.path(int_data_path, NAME, CURRENT_RUN, "Visual+Style+Impressions_May+29,+2023_09.45_num.csv")
test_data_text <- file.path(int_data_path, NAME, CURRENT_RUN, "Visual+Style+Impressions_May+29,+2023_09.45_text.csv")
```

Pilot set (n=8) data files.
```{r}
CURRENT_RUN <- "1-1_pilot"

pilot_prolific <- file.path(int_data_path, NAME, CURRENT_RUN, "prolific_export_638fb8ef63b505b75b7a60e2.csv")
pilot_screener <- file.path(int_data_path, NAME, CURRENT_RUN, "Visual+Style+Impressions +Screener_May+30,+2023_08.29.csv")
pilot_data_num <- file.path(int_data_path, NAME, CURRENT_RUN, "Visual+Style+Impressions_May+30,+2023_08.30.csv")
pilot_data_text <- file.path(int_data_path, NAME, CURRENT_RUN, "Visual+Style+Impressions_May+30,+2023_08.30(1).csv")
```

Main set (n=19) data files
```{r}
# CURRENT_RUN <- "1-2_main"
# 
# main_prolific <- file.path(int_data_path, NAME, CURRENT_RUN, "prolific_export_639a300a1d6149180ddaad11.csv")
# main_screener <- file.path(int_data_path, NAME, CURRENT_RUN, "Visual+Style+Selection +Screener_December+16,+2022_14.19.csv")
# main_data_num <- 
#   file.path(int_data_path, NAME, CURRENT_RUN, "Visual+Style+Selection_December+16,+2022_14.32.csv")
# main_data_text <- 
#   file.path(int_data_path, NAME, CURRENT_RUN, "Visual+Style+Selection_December+16,+2022_14.32(1).csv")
```

Final set (n=10 + 3) data files
```{r}
# CURRENT_RUN <- "1-3_final"
# 
# final_prolific <- file.path(int_data_path, NAME, CURRENT_RUN, "prolific_export_639cfab1514594c1843130f3.csv")
# # final_screener <- file.path(int_data_path, NAME, CURRENT_RUN, "Visual+Style+Selection +Screener_January+6,+2023_08.27.csv")
# # final_data_num <- file.path(int_data_path, NAME, CURRENT_RUN, "Visual+Style+Selection_January+6,+2023_08.30.csv")
# # final_data_text <- file.path(int_data_path, NAME, CURRENT_RUN, "Visual+Style+Selection_January+6,+2023_08.30(1).csv")
# 
# CURRENT_RUN <- "1-3_final/v2"
# 
# finalv2_prolific <- file.path(int_data_path, NAME, CURRENT_RUN, "prolific_export_63b85d2171744e79cbbe40e9.csv")
# final_screener <- file.path(int_data_path, NAME, CURRENT_RUN, "Visual+Style+Selection +Screener_January+6,+2023_12.47.csv")
# final_data_num <- file.path(int_data_path, NAME, CURRENT_RUN, "Visual+Style+Selection_January+6,+2023_12.48.csv")
# final_data_text <- file.path(int_data_path, NAME, CURRENT_RUN, "Visual+Style+Selection_January+6,+2023_12.48(1).csv")
```


## (*T) Check Test Data 
Using simulated (pre-pilot, test) data, check data labels and prep code for cleaning data (columns, etc). During this iterative process, go back to Qualtrics survey and update codes and labels where necessary to ensure clean output data.

Some of this code adapted for wrangling participant data.
```{r}
# NOTE: Unfinished data doesn't appear in the export file until X days later. That's why the data may seem to change if I export new data later.

# Use numeric data for main task
n1b_data <- read_csv(test_data_num)  %>% 
  filter(Finished!=0) %>%
  select(-StartDate:-UserLanguage) %>% # Remove metadata columns (first several). See raw data for columns Progress, Duration, Finished, RecordedDate
  slice(-2)  # Remove unnecessary question header rows (1,2)
n1b_data

# Use text data for subject data
n1b_data_text <- read_csv(test_data_text)  %>% 
  filter(Finished!="False") %>%
  select(-StartDate:-UserLanguage) %>% # Remove metadata columns (first several)
  slice(-2) # Remove unnecessary question header rows (1,2)
n1b_data_text
```

```{r}
# Check column names
# n1b_data %>%
#   colnames()
```

```{r}
# Get randomized images order list per subject
# Check for even distribution
n1b_data %>%
  select(contains("Q2.5")) %>% select(contains("DO")) %>% slice(-1) %>%
  mutate(subj=1:n(), .before=1) %>% # Add temp subj number for simulated data
  pivot_longer(cols=2:last_col(), names_to=c(NA, NA, "Photo_Number"), names_sep="_", values_to = "DO") %>% type.convert() %>%
  arrange(subj, DO) %>% drop_na(DO) %>%
  pivot_wider(subj, names_from = DO, names_prefix = "Trial", values_from = Photo_Number)
  
```

```{r}
# Get informative question labels
q_labels <- 
  n1b_data %>%
  select(`1_Q3.1_1`:`30_Q3.12`) %>% select(-contains("DO")) %>% # select only looped trials, excl, DisplayOrder
     slice(1) %>%
  pivot_longer(cols=everything(), names_to=c("Photo_Number", "Question_Number", "Question_Part_Number", NA), names_sep="_", values_to = "q_label") %>%
  # Since number of dashes and <> location aren't consistent, need to remove everything between < > and extra -
  mutate(q_label = gsub("<.*>", "", q_label)) %>%
  mutate(q_label = gsub("^(\\s*-\\s*)", "", q_label)) %>%
mutate(q_label = gsub("(-\\s+.*\\s+-)", "-", q_label)) %>%
  separate(q_label, into= c("Question", "Question_Part"), sep = "-", extra="merge")
q_labels 
```

```{r}
# Get question data + merge with informative question labels
test_data <- n1b_data %>%
  select(`1_Q3.1_1`:`30_Q3.12`) %>% select(-contains("DO")) %>% # select only looped trials, excl, DisplayOrder
  slice(-1) %>% # remove second header
  mutate(subj=1:n(), .before=1) %>% # Add temp subj number for simulated data
  pivot_longer(cols=2:last_col(), names_to=c("Photo_Number", "Question_Number", "Question_Part_Number", NA), names_sep="_", values_to = "responses") %>%
  full_join(q_labels, .)
test_data
```
```{r}
# Check question labels for all questions (even those not shown to participants, are NA)
test_data %>%  group_by(subj) %>%  count() #870
test_data %>%  group_by(subj, Photo_Number) %>%  count() # 29
test_data %>%  group_by(subj, Photo_Number, Question) %>%  count() 
test_data %>%  group_by(subj, Photo_Number, Question, Question_Part) %>%  count()
```
```{r}
# Get only data shown to participants (i.e., drop NA)
test_data_clean <- test_data %>%
  drop_na(responses)

# Check n of total questions by subj and photo
# For rough check (not very meaningful)
test_data_clean %>% group_by(subj) %>%  count()
test_data_clean %>%  group_by(subj, Photo_Number) %>% count() %>% type_convert() %>% arrange(subj, Photo_Number) # 29
test_data_clean %>% group_by(Photo_Number)%>% count() %>% type_convert() %>% arrange(Photo_Number)

# Check n of trials by subj and photo 
# For confirming even presentation (randomization) of photos
# Total presented/answered photos (end goal: 600)
test_data_clean %>% select(subj, Photo_Number) %>% distinct() %>% count()
# Total presented/answered photos per participant (process/end goal: 10 per subject)
test_data_clean %>% select(subj, Photo_Number) %>% distinct() %>% count(subj)
# Total presented/answered participants per photo (end goal: 20 per photo)
test_data_clean %>% select(subj, Photo_Number) %>% distinct() %>% count(Photo_Number) %>% type_convert() %>% arrange(Photo_Number)

```




# Pre-Process Screener Data

## Read, Wrangle

```{r}
n1b_screener_data <- read_csv(pilot_screener) %>%
# Remove metadata columns (first several)
  select(-StartDate:-UserLanguage) %>%
  # Remove uneccessary question header rows (1,2)
  slice(-1:-2) %>%
  unite("Ethnicity", Ethnicity_9:Ethnicity_14, sep=",", na.rm=TRUE, remove=FALSE) %>%
relocate(Device, .after = Ethnicity) %>%
  rename(`Participant id` = Prolific_ID) %>%
  #TEMP: Remove returned/non-consent participants, bad participants, outliers.
  filter(!(PROLIFIC_PID%in% c("62a15df1dd6fa394ea04f063", # Pilot returned
                              "609b6c918ad180505fefd919")))
  #distinct() # Remove duplicate rows
  
n1b_screener_data 
# View(screener_data)
```
```{r}
# Read in Prolific "Demographic data" from the study page
n1b_prolific_demo <- 
  read_csv(pilot_prolific) %>% mutate(Run="pilot") %>%
  # full_join(read_csv(main_prolific) %>% mutate(Run="main")) %>% 
  # full_join(read_csv(final_prolific) %>% mutate(Run="final")) %>%
  # full_join(read_csv(finalv2_prolific) %>% mutate(Run="finalv2")) %>%
  mutate(Time_in_min=`Time taken`/60, .after=`Time taken`)  
n1b_prolific_demo
```


```{r}
# Compare screener to prolific demographic
n1b_screener_v_prolific <-
  n1b_screener_data %>% full_join(n1b_prolific_demo, by="Participant id")  %>% 
  select(
    Run,
    `Participant id`,
    Time_in_min,
    State_Born, `U.s state/territory of birth`,
    State_Current, `Current u.s state of residence`,
    Ethnicity_screen=Ethnicity.x, Ethnicity_prolific=Ethnicity.y, `Ethnicity simplified` 
    #, .after=`Participant id`
  ) #%>%
  # drop_na(Run)
  
n1b_screener_v_prolific

# Scan for duplicated participant issues
n1b_screener_v_prolific %>% arrange(`Participant id`)
```


## Check, Summarize
Check the prescreener data for consistency with the main data.
### Sample Check
#### Time Taken
```{r}
#Time_in_min
n1b_screener_v_prolific %>%
  summarize(mean_Time=mean(Time_in_min), median_Time=median(Time_in_min), 
            min_Time=min(Time_in_min), max_Time=max(Time_in_min),
            sd_Time=sd(Time_in_min)) %>%
  mutate(low_cutoff=min_Time-sd_Time*3, high_cutoff=max_Time+sd_Time*3)
```
#### Region
```{r}
# Sample Counts: Region
n1b_screener_data %>%
  distinct() %>% # remove duplicate rows
  count(State_Current,State_Born)
```
#### Ethnicity
```{r}
# Sample Counts: Ethnicity
n1b_screener_data %>%
  distinct() %>% # remove duplicate rows
  count(Ethnicity)
```

#### Device
```{r}
# Sample Counts: Device
n1b_screener_data %>%
  # filter(PROLIFIC_PID %in% survey_demo$Prolific_ID) %>%
  distinct() %>% # remove duplicate rows
  count(Device)
```

#### By-Participant Check
```{r}
participant_list <- n1b_screener_v_prolific %>% filter(Run=="pilot") %>%  pull(`Participant id`)
participant_list
```

```{r}
current_participant <- "5f7d4a2c5db79d21c7d07240" #participant_list[3]

n1b_screener_data %>%  filter(PROLIFIC_PID == current_participant) #Prolific_ID

n1b_screener_v_prolific %>%  filter(`Participant id` == current_participant) #Prolific_ID

```



# Pre-Process Main Data
## Read
Read in exported data, and check what it looks like.

NOTE: Remove data from subjects who did not complete the study ("returned" on Prolific) or have been identified to be outliers, not following instructions, not fulfilling my participant requirements, etc. Outliers are identified in a later section below (Outlier Check), while participant requirements are checked in the data from the questionnaire.

```{r}
# Use numeric data for main task
  # NOTE: Unfinished data doesn't appear in the export file until X days later. That's why the data may seem to change if I export new data later.

n1b_data <- read_csv(pilot_data_num)  %>% 
  filter(Finished!=0) %>%
  # Remove metadata columns (first several). See raw data for columns Progress, Duration, Finished, RecordedDate + question header rows (1,2) + function cols
  select(-StartDate:-UserLanguage) %>% 
  slice(-2) %>% select(-Q1.2,-starts_with("Ex")) 
  # Remove returned/non-consent participants, bad participants, outliers.
n1b_data %>% colnames()


# Use text data for subject data
n1b_data_text <- read_csv(pilot_data_text)  %>% 
  # NOTE: Unfinished data doesn't appear in the export file until X days later. That's why the data may seem to change if I export new data later.
  filter(Finished!="False") %>%
  # Remove metadata columns (first several) + question header rows (1,2)
  select(-StartDate:-UserLanguage) %>% 
  slice(-2)  %>% select(-Q1.2,-starts_with("Ex")) 
n1b_data_text
```

```{r}
n1b_data %>% pull(PROLIFIC_PID)
```

See notes here for breakdown of headers/metadata per column, which inform the next processing steps.
```{r}
# How to split up question header into interpretable info and match up with the actual photo that was shown/selected.

# Header examples
## Actual question
#1) 1_Q5.1_1
#2) <img src="https://umich.qualtrics.com/ControlPanel/Graphic.php?IM=IM_6g7DQpb7a7wYUWa" /> - PR_1a_B - ${lm://Field/1}
#3) {"ImportId":"1_QID606","choiceId":"1"}

## Randomization order
#1) 1_Q5.1_DO_1
#2) PR_1a_B - Display Order - ${lm://Field/1}
#3) {"ImportId":"1_QID606_DO","choiceId":"1"}

## Breakdown
# In row #1, first number before the underscore is the LOOP NUMBER (i.e. LOOP 1)
# Second after the first underscore, it's the question number, which I don't need (i.e., Q5.1)
# Third after the second underscore, it's the CHOICE ID which isn't meaningful because it's ordered wrong, so I don't need it either (i.e., 1)

# In row #2, first before the (space)dash(space) is the "Field 1" item of that Loop, which I don't need because I have the list code...
# Second, after the first (space)dash(space) is the label I (painstakingly) added in. Use this to split off three pieces of info: (1) PR = pseudorandom, (2) question code (i.e., 1a = "Asian American"), (3) list code (i.e., B) 
# Third, after the second (space)dash(space) is the particular Field/choice for that column (i.e., ${lm://Field/1} = Field 1), which I can link to the exact photo ID/name by mapping to a separate decoding CSV (see below)

# To construct the decoding CSV, take the List matrices I created in the SpAAC: Visual Stimuli google sheets. Create a long format file that includes the  following columns: (1) List [A-J], (2) Loop [1-9], (3) Field [1-8], (4) Image link, (5) URL, (6) Qualtrics ID, (7) [Local] Filename (or Code, e.g., AAW-2)

```

Next, read in image/filename decoding information that was originally constructed in Google sheets (SpAAC: Visual Stimuli) and downloaded as CSV.
```{r}
# Read in image decoding file
n1b_codes <- read.csv(file.path(stim_data_path, NAME, "02-records","SpAAC Visual Stimuli - N1b_Stims.csv")) %>%
  mutate(Photo_Number = seq(1:n()), .before="Critical.Filler")
n1b_codes
```

## Wrangle

### (*TEMP?) Check Basic Info
Get just the responses with informative question labels
```{r}
# Get informative question labels
q_labels <- 
  n1b_data %>%
  select(`1_Q3.1_1`:`30_Q3.12`) %>% select(-contains("DO")) %>% # select only looped trials, excl, DisplayOrder
     slice(1) %>%
  pivot_longer(cols=everything(), names_to=c("Photo_Number", "Question_Number", "Question_Part_Number", NA), names_sep="_", values_to = "q_label") %>%
  # Since number of dashes and <> location aren't consistent, need to remove everything between < > and extra -
  mutate(q_label = gsub("<.*>", "", q_label)) %>%
  mutate(q_label = gsub("^(\\s*-\\s*)", "", q_label)) %>%
mutate(q_label = gsub("(-\\s+.*\\s+-)", "-", q_label)) %>%
  separate(q_label, into= c("Question", "Question_Part"), sep = "-", extra="merge")
q_labels 

# Get question data + merge with informative question labels
n1b_response_data <- n1b_data %>%
  select(`1_Q3.1_1`:`30_Q3.12`) %>% select(-contains("DO")) %>% # select only looped trials, excl, DisplayOrder
  slice(-1) %>% # remove second header
  mutate(subj=1:n(), .before=1) %>% # Add temp subj number for simulated data
  pivot_longer(cols=2:last_col(), names_to=c("Photo_Number", "Question_Number", "Question_Part_Number", NA), names_sep="_", values_to = "responses") %>%
  full_join(q_labels, .)
n1b_response_data
```
Check the number of by-subject and by-photo counts
```{r}
# Get only data shown to participants (i.e., drop NA)
n1b_response_data_clean <- n1b_response_data %>%
  drop_na(responses)

# Check n of trials by subj and photo 
# For confirming even presentation (randomization) of photos

# Total presented/answered photos (end goal: 600)
n1b_response_data_clean %>% select(subj, Photo_Number) %>% distinct() %>% count()
# Total presented/answered photos per participant (process/end goal: 10 per subject)
n1b_response_data_clean %>% select(subj, Photo_Number) %>% distinct() %>% count(subj)
# Total presented/answered participants per photo (end goal: 20 per photo)
n1b_response_data_clean %>% select(subj, Photo_Number) %>% distinct() %>% count(Photo_Number) %>% type_convert() %>% arrange(Photo_Number)

```

### Subject Data
Before moving on, check the Task short-answer reflections and Demographic data + Randomization data.
```{r}
colnames(n1b_data_text)[[1400]]
```


```{r}
# Extract relevant Info from 
n1b_subj <- n1b_data_text %>%
  # Get Part 1 end and Demographics
  select('Q4.3':'VERSION') %>% 
  
  janitor::row_to_names(1, remove_rows_above = FALSE) %>% # Uses first row as colnames
  type_convert()
n1b_subj
```

#### Conditions
Process randomization/condition information. Check that randomization is working (e.g., displaying randomly, evenly). Includes version and photo numbers by participant and trial.
```{r}
n1b_subj_cond <- n1b_subj %>% 
  select(PROLIFIC_PID, VERSION) %>%
  full_join(
    # Get randomized images order list per subject
    n1b_data %>%
    select(PROLIFIC_PID, contains("Q2.5_DO")) %>% slice(-1) %>%
    pivot_longer(cols=2:last_col(), names_to=c(NA, NA, "Photo_Number"),
                 names_sep="_", values_to = "DO") %>% type.convert() %>%
      arrange(PROLIFIC_PID, DO) %>% drop_na(DO) %>%
      pivot_wider(PROLIFIC_PID, names_from = DO, names_prefix = "Trial",
                  values_from = Photo_Number)
  )
n1b_subj_cond 

## UNCOMMENT to check a participant
# n1b_subj_cond %>%  filter(PROLIFIC_PID=="596fc4717008ef000109703d")
```


Process Part 1 End responses about the task.
```{r}
# View
(n1b_subj_p1 <- n1b_subj %>% select(PROLIFIC_PID, WhatTaskAbout:TaskNotice))
```
Process Part 2 responses about the personal demographics.
```{r}
n1b_subj_p2 <- n1b_subj %>% select(PROLIFIC_PID, Age:Education) %>%
  # Convert -99 to NAs
  mutate(across(where(is.numeric), ~na_if(., -99))) %>%
  mutate(across(where(is.character), ~na_if(., "-99"))) %>%
  rename_with(., ~ gsub(" - Selected Choice", "", .x, fixed=TRUE)) %>%
  # Clean text responses
  mutate(Gender=tolower(Gender), Ethnicity=tolower(Ethnicity)) %>%
  #mutate(Gender=gsub(" ", "", Gender), Ethnicity=gsub("-", " ", Ethnicity)) %>%
  mutate(Gender=mgsub(Gender, c("^female|^woman", "^male|^man"), c("f", "m"), fixed=FALSE)) %>%
  mutate(Ethnicity=mgsub(Ethnicity, c(" american", "/"), c("", ", "), fixed=TRUE))
n1b_subj_p2
```
#### Summary
#### By-Sample Check
```{r}
# Total Participant entries
n1b_subj_p2 %>%
  count()

# Total Participants per condition
n1b_subj_p2 %>% full_join(n1b_subj_cond, .) %>%
  count(VERSION)
```
##### Age
```{r}
# Age
n1b_subj_p2 %>%
  summarize(mean_Age=mean(Age), median_Age=median(Age), min_Age=min(Age), max_Age=max(Age))
```
```{r}
# Visualize Age
n1b_subj_p2 %>%
  ggplot() +  gg_theme() +
  geom_histogram(aes(x=Age), binwidth=1, alpha=0.7)
```


##### Gender
```{r}
# Gender overall
n1b_subj_p2 %>%
  count(Gender, GenderCat)
```

```{r}
# Gender by Age, colored
n1b_subj_p2 %>%
  ggplot() +  gg_theme() +
  geom_histogram(aes(x=Age, fill=GenderCat), binwidth=1, alpha=0.7)

# Visualize Gender
n1b_subj_p2 %>%
  ggplot() +
  gg_theme() +
  geom_bar(aes(x=GenderCat, fill=GenderCat), alpha=0.7) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

```

##### Ethnicity
```{r}
# EthnicityCat
n1b_subj_p2 %>%
  count(EthnicityCat) %>%
  arrange(-n)

# Specific Ethnicity
n1b_subj_p2 %>%
  count(Ethnicity, EthnicityCat) %>%
  arrange(-n)

# Other: Ethnicity by Gender 
n1b_subj_p2 %>%
  count(Ethnicity, Gender) %>%
  arrange(-n) %>%
  pivot_wider(., Ethnicity, names_from = "Gender", values_from = "n") %>%
  mutate(across(where(is.integer), ~ coalesce(.x, 0L))) %>%
  group_by(Ethnicity) %>% mutate(total=sum(m, f), .after=Ethnicity)
```
```{r}
# Visualize Ethnicity
# By Gender
n1b_subj_p2 %>%
  group_by(Ethnicity) %>% mutate(Ethnicity_n=n()) %>% ungroup() %>%
  ggplot() +
  gg_theme() +
  geom_bar(aes(x=reorder(Ethnicity, -Ethnicity_n), fill=Gender, linetype=EthnicityCat), alpha=0.7) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  labs(x="Ethnicity")

# With Ethnicity Cat
n1b_subj_p2 %>%
  group_by(Ethnicity) %>% mutate(Ethnicity_n=n()) %>% ungroup() %>%
  ggplot() +
  gg_theme() +
  geom_bar(aes(x=reorder(Ethnicity, -Ethnicity_n), fill=EthnicityCat), alpha=0.7) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +
  labs(x="Ethnicity")
```


##### Location
```{r}
# # Check location info for summary statement
n1b_subj_p2_loc <-
  n1b_subj_p2 %>%
  select(PROLIFIC_PID, starts_with("Location")) %>%
  mutate(across(everything(), as.character)) %>%
  rename_with(., ~ gsub(".*(\\d)", "\\1", .x)) %>% # Remove everything before the first digit, but keep the digit (via the parenthesis and \\1)
  pivot_longer(cols = 2:last_col(), names_to = c("Loc", "Info"), names_sep=" - ", values_to = "Response") %>%
  pivot_wider(id_cols=PROLIFIC_PID:Loc, names_from = Info, values_from = Response) 
# n1b_subj_p2_loc # <- UNCOMMENT to view
```
#### By-Participant Check
```{r}
participant_list <- n1b_screener_v_prolific %>% filter(Run=="pilot") %>%  pull(`Participant id`)
participant_list
```
Run the following to screen participant data. Mainly, check that they fit the demographic criteria.

Pilot = 1:8
Main1 = 8:
```{r}
# Print all in range
for (i in 1:length(participant_list)){
  current_participant <- participant_list[i]
    
  # UNCOMMENT TO view subj data by subject
  # print(n1b_subj_p2 %>% filter(PROLIFIC_PID == current_participant))
  
  # View locations by subject
  print(
    n1b_subj_p2_loc %>%  filter(PROLIFIC_PID == current_participant) %>%
    filter(!(is.na(`from Age`)))
  )
}
```

```{r}
# Check single participant
current_participant <- "5f7d4a2c5db79d21c7d07240" # OR e.g. participant_list[3]

# View subj data by subject
n1b_subj_p2 %>% filter(PROLIFIC_PID == current_participant)

# View locations by subject
n1b_subj_p2_loc %>%  filter(PROLIFIC_PID == current_participant) %>%
  filter(!(is.na(`from Age`)))
```
<!-- UPDATE THIS STATEMENT: All participants were living in California* (based on pre-screen) at the time. -->
```{r}
# Notes on Participant Locations.
# PILOT

```


### Main Data

Next, get just the response data with informative question labels. To be able to extract info from not only header but also first row, isolate the first row via slice(). Then, wrangle to get all the relevant info.

After that, isolate the actual data via slice (2nd row onwards) then pivot_longer and merge in by-question information (note: the original pivot_longer should match on both datatables). Drop unseen/unshown questions/blocks (i.e. NAs). Then, merge in the image codes!

NOTE: Can drop Question_Number and Question_Part_Number if not useful as shorthand.

```{r}
# Get informative question labels from header and first row

n1b_response_info <-  n1b_data %>%
  select(`1_Q3.1_1`:`30_Q3.12`) %>% select(-contains("DO")) %>% # select only looped trials, excl, DisplayOrder
     slice(1) %>%
  pivot_longer(cols=everything(), names_to=c("Photo_Number", "Question_Number", "Question_Part_Number", NA), names_sep="_", values_to = "q_label") %>%
  # Since number of dashes and <> location aren't consistent, need to remove everything between < > and extra - rather than just separate() or str_extract()
  mutate(q_label = gsub("<.*>", "", q_label)) %>%
  mutate(q_label = gsub("^(\\s*-\\s*)", "", q_label)) %>%
mutate(q_label = gsub("(-\\s+.*\\s+-)", "-", q_label)) %>%
  separate(q_label, into= c("Question", "Question_Part"), sep = "-", extra="merge")
n1b_response_info

# Get question data + merge with informative question labels
n1b_responses <- n1b_data %>%
  select(PROLIFIC_PID, `1_Q3.1_1`:`30_Q3.12`) %>% select(-contains("DO")) %>% # select only looped trials, excl, DisplayOrder
  slice(-1) %>% # remove second header
  pivot_longer(cols=2:last_col(), names_to=c("Photo_Number", "Question_Number", "Question_Part_Number", NA), names_sep="_", values_to = "Response") %>%
  full_join(n1b_response_info, .) %>% relocate(PROLIFIC_PID) %>%
  
  mutate(Response=ifelse(Response==-99,NA,Response)) %>% drop_na(Response) %>% # Drop unpresented + unanswered qs
  mutate(Response = case_when(Question=="Recognize" & Response=="2" ~ "No",
                              Question=="Recognize" & Response=="1" ~ "Yes",
                              TRUE ~ Response)) %>%
  type_convert() %>% # Auto-Convert number character columns to numeric
  full_join(., n1b_codes) %>% select(-Code) %>%
  mutate(across(where(is.character), as.factor))
n1b_responses
summary(n1b_responses)
# View(n1b_responses)
```

Sanity Check: Check the number of by-subject and by-photo counts. Does randomization seem to be working alright?
```{r}
# Check n of trials by subj and photo 
# For confirming even presentation (randomization) of photos

# Total presented/answered photos (end goal: 600)
n1b_responses %>% select(PROLIFIC_PID, Photo_Number) %>% distinct() %>% count()
# Total presented/answered photos per participant (process/end goal: 10 per subject)
n1b_responses %>% select(PROLIFIC_PID, Photo_Number) %>% distinct() %>% count(PROLIFIC_PID)
# Total presented/answered participants per photo (end goal: 20 per photo)
n1b_responses %>% select(PROLIFIC_PID, Photo_Number) %>% distinct() %>% count(Photo_Number) %>% arrange(Photo_Number)

```


#### Summary
Make a targeted dataframe with just the useful/relevant columns for easier viewing.
```{r}
# Select relevant columns only.
n1b_responses_selected <- n1b_responses %>%
  select(PROLIFIC_PID, Question, Question_Part, Condition, Image_Cat, Image, Response) %>%
  mutate(across(where(is.character), as.factor)) %>%
  mutate(Response = case_when(Question=="Recognize" & Response=="2" ~ "No",
                              Question=="Recognize" & Response=="1" ~ "Yes",
                              TRUE ~ Response)) 
n1b_responses_selected
# View(n1b_responses_selected)
summary(n1b_responses_selected)
```

#### Check
Check and explore the data here.

Error check, i.e., manually view strange things in the data to fix them above
```{r}
# n1b_responses %>%
#   filter(is.na(Image))
# 
# n1b_responses_selected %>%
#   filter(Response==-99)

# View one participant/slice
# n1b_responses_selected %>%
#   filter(PROLIFIC_PID==5) %>%
#   View()
```

##### By-Sample Check
```{r}
# Conditions, sample sizes, sample means, time taken, outliers(?)
# summary(n1b_responses)
summary(n1b_responses_selected)
```
##### By-Participant Check
Get the participants list.
```{r}
participant_list <- n1b_screener_v_prolific %>% filter(Run=="pilot") %>%  pull(`Participant id`)
participant_list
```

```{r}
n1b_responses %>% pull(Question) %>% unique()
```

Run the following iteratively to screen participant data. Mainly, check that they seemed to answer the questions in good faith. If not, add notes below. If it's all fine, then accept their submission.
```{r}
current_participant <- participant_list[8] #"5f7d4a2c5db79d21c7d07240" 

current_responses <- n1b_responses %>% 
  select(PROLIFIC_PID, Question, Question_Part, Image, Response) %>% 
  filter(PROLIFIC_PID == current_participant) %>%
  mutate(Response = case_when(Question=="Recognize" & Response=="2" ~ "No",
                              Question=="Recognize" & Response=="1" ~ "Yes",
                              TRUE ~ Response)) 

current_responses %>% filter(Question=="Impressions") %>% pivot_wider(id_cols = c(PROLIFIC_PID, Image), names_from = Question_Part, values_from = Response)

# Non-numeric responses
current_responses %>% filter(Question=="Age") %>%
  filter(Response!=0) %>% select(PROLIFIC_PID, Image, Question_Part)
  # pivot_wider(id_cols = c(PROLIFIC_PID, Image), names_from = Question_Part, values_from = Response)

current_responses %>% filter(Question=="Occupation") %>% select(-contains("Question_Part"))

current_responses %>% filter(Question=="Activities") %>% select(-contains("Question_Part"))

current_responses %>% filter(Question=="GrewUp") %>% select(-contains("Question_Part"))

current_responses %>% filter(Question=="Ethnicity") %>% select(-contains("Question_Part"))

current_responses %>% filter(Question=="Speech") %>% select(-contains("Question_Part"))

current_responses %>% filter(Question=="Recognize") %>% select(-contains("Question_Part"))

```

```{r}
# Rating responses
current_ratings <- current_responses %>% filter(Question=="Ratings") %>% select(-"Question") %>% select(-PROLIFIC_PID) %>% type_convert()

current_ratings %>%
  filter(Question_Part == str_match(Question_Part, ".*American:.*")) %>% select(Image, Scale=Question_Part, Response)

current_ratings %>%
  filter(Question_Part == str_match(Question_Part, ".*American-.*")) %>% select(Image, Scale=Question_Part, Response)
```

```{r}
current_ratings %>% summary()

current_ratings %>% group_by(Image) %>% summarize(min=min(Response), max=max(Response), mean=mean(Response), median=median(Response))

current_ratings %>% group_by(Question_Part) %>% summarize(min=min(Response), max=max(Response), mean=mean(Response), median=median(Response))

current_ratings %>% summarize(min=min(Response), max=max(Response), mean=mean(Response), median=median(Response))

```

```{r}
# Response Patterns Review Notes

```

## Summarize
### Recognize
Sanity check that no people were recognized.
```{r}
n1b_responses_selected %>% filter(Question=="Recognize") %>% count(Response)
```
### Descriptors
```{r}
n1b_descriptors <-
  # n1b_responses %>% 
  # select(PROLIFIC_PID, Question, Question_Part, Image, Response) %>% 
  n1b_responses_selected %>%
  filter(Question=="Impressions") %>%
  select(- PROLIFIC_PID:-Question_Part) %>%
  # text cleaning
  mutate(Response = tolower(Response)) %>%
  mutate(Response = mgsub(Response, c("-"), c(""), fixed=TRUE)) %>%
  mutate(Response = mgsub(Response, c("inetlligent"), c("intelligent"), fixed=TRUE)) %>% # typos
  # get counts
  add_count(Image, name="total_image_n") %>% add_count(Response, name="total_word_n") %>% 
    add_count(Image, Response, name="image_word_n")
n1b_descriptors
```
```{r}
# Check for certain types of patterns to clean
# n1b_descriptors %>%  filter(Response == str_match(Response, ".* .*"))
```

```{r}
# Total descriptor words
n1b_descriptors %>% count(name="total_words")

# Total unique/different words
n1b_descriptors %>% count(Response) %>% count(name="unique_words")

# Total unique/different words per condition
n1b_descriptors %>% count(Condition,Response) %>% count(Condition, name="unique_words_per_condition")
```

```{r}
# Top words used
n1b_descriptors %>% count(Response, sort=TRUE)

# Top words used for a certain image
n1b_descriptors %>% count(Image, Response, sort=TRUE)

# Top words used for a certain condition's images
n1b_descriptors %>% count(Condition, Response, sort=TRUE) %>% pivot_wider(names_from=Condition, values_from = n)

```

```{r}
ethAsian_words <- n1b_descriptors %>% filter(Condition=="ethAsian") %>% count(Condition, Response, sort=TRUE)
msAsian_words <- n1b_descriptors %>% filter(Condition=="msAsian") %>% count(Condition, Response, sort=TRUE)
msWhite_words <- n1b_descriptors %>% filter(Condition=="msWhite") %>% count(Condition, Response, sort=TRUE)
```

```{r}
# Shared words
Asian_words <- intersect(select(ethAsian_words, Response), select(msAsian_words,Response)) 
shared_words <- intersect(Asian_words, select(msWhite_words, Response)) 
ms_words <- intersect(select(msWhite_words, Response), select(msAsian_words,Response))
nonmsA_words <- intersect(select(msWhite_words, Response), select(ethAsian_words,Response))

shared_words %>% rename("Words in all personae"=Response)
nonmsA_words %>% setdiff(.,shared_words) %>% rename("Words only in both msWhite and ethAsian"=Response)
ms_words %>% setdiff(.,shared_words) %>% rename("Words only in Mainstream personae (both msWhite and msAsian)"=Response)
Asian_words %>% setdiff(.,shared_words) %>% rename("Words only in Asian personae (both ethAsian and msAsian)"=Response)
```
```{r}
# Different words
ethAsian_words_only <- setdiff(select(ethAsian_words, Response), select(msAsian_words, Response)) %>% setdiff(., select(msWhite_words, Response)) 
msAsian_words_only <- setdiff(select(msAsian_words, Response), select(ethAsian_words, Response)) %>% setdiff(., select(msWhite_words, Response)) 
msWhite_words_only <- setdiff(select(msWhite_words, Response), select(ethAsian_words, Response)) %>% setdiff(., select(msAsian_words, Response)) 

ethAsian_words_only %>% rename("Words in ethAsian only"=Response)
msAsian_words_only%>% rename("Words in msAsian only"=Response)
msWhite_words_only %>% rename("Words in msWhite only"=Response)
```

```{r}
# Show individual condition top words
ethAsian_words %>% filter(n>1) %>% ggplot(aes(x=reorder(Response, n), y=n)) + geom_col() + coord_flip() + labs(title="ethAsian adjectives", x= "Responses", y="No. of occurences")
msAsian_words %>% filter(n>1) %>%ggplot(aes(x=reorder(Response, n), y=n)) + geom_col() + coord_flip() + labs(title="msAsian adjectives", x= "Responses", y="No. of occurences")
msWhite_words %>% filter(n>1) %>%ggplot(aes(x=reorder(Response, n), y=n)) + geom_col() + coord_flip() + labs(title="msWhite adjectives", x= "Responses", y="No. of occurences")
```
```{r}
# Show individual condition unique top words
ethAsian_words %>% filter(Response %in% pull(ethAsian_words_only)) %>% ggplot(aes(x=reorder(Response, n), y=n)) + geom_col() + coord_flip() + labs(title="ethAsian adjectives", x= "Responses", y="No. of occurences")
msAsian_words %>% filter(Response %in% pull(msAsian_words_only)) %>% ggplot(aes(x=reorder(Response, n), y=n)) + geom_col() + coord_flip() + labs(title="msAsian adjectives", x= "Responses", y="No. of occurences")
msWhite_words %>% filter(Response %in% pull(msWhite_words_only)) %>% ggplot(aes(x=reorder(Response, n), y=n)) + geom_col() + coord_flip() + labs(title="msWhite adjectives", x= "Responses", y="No. of occurences")
```




### Age
Get proportion selections per age category for each image.
```{r}
 n1b_age <- n1b_responses %>% 
  select(PROLIFIC_PID, Question, Question_Part, Image, Response) %>% 
  filter(Question=="Age") %>% 
  pivot_wider(id_cols = c(PROLIFIC_PID, Image), names_from = Question_Part, values_from = Response) %>% 
  mutate(across(Teens:`Over 40`, ~ as.numeric(as.character(.x)))) %>% 
  # Get proportions out of total responses (props add up to over 100 b/c multiple selections)
  add_count(Image) %>% group_by(Image, n) %>% 
  summarize(across(Teens:`Over 40`, sum)) %>% 
  mutate(across(Teens:`Over 40`, ~ .x/n)) %>%
  pivot_longer(Teens:`Over 40`, names_to = "Age", values_to = "prop") %>%
  # Drop values where none selected
  filter(prop>0) %>%  arrange(-prop, .by_group=TRUE) %>% #ungroup() %>%
  # filter(prop>0.5) # Option 1: Keep values where more than half of participants selected
  slice_max(prop) # Option 2: Keep only highest value (including ties)
n1b_age

# Get age consensus based on majority decision
n1b_age %>% pivot_wider(Image:n, names_from = Age, values_from = prop) %>% 
  relocate(Teens, .after=n) %>%
  mutate(across(`Teens`:`30s`, ~ ifelse(!is.na(.x), cur_column(), NA) )) %>%
  unite(Perceived_Age, `Teens`:`30s`, sep=',', na.rm=TRUE)
```

### Occupation
```{r}
n1b_occupation <-
  n1b_responses_selected %>% filter(Question=="Occupation") %>% 
  # text cleaning
  mutate(Response = tolower(Response)) 
  
n1b_occupation %>% count(Response, sort=TRUE) %>% add_count(name="n_unique")
n1b_occupation %>% count(Condition, Response, sort=TRUE) %>% pivot_wider(names_from=Condition, values_from = n)

```

### Activities
```{r}
n1b_activities <-
  n1b_responses_selected %>% filter(Question=="Activities") %>% 
  # text cleaning
  mutate(Response = tolower(Response)) 
  # Split responses by comma, get multiple long responses per row/image, then count
  
n1b_activities %>% count(Response, sort=TRUE) %>% add_count(name="n_unique")
n1b_activities %>% count(Condition, Response, sort=TRUE) %>% pivot_wider(names_from=Condition, values_from = n)

```

### (+) GrewUp
```{r}
n1b_grewup <-
  n1b_responses_selected %>% filter(Question=="GrewUp") %>% select(-Question_Part) %>%
  # text cleaning
  mutate(Response = str_trim(tolower(Response))) %>%
  mutate(Response = gsub("(.*)\\s*,\\s*usa", "\\1", Response)) %>% # keep everything before ', usa'
  mutate(Response = mgsub(Response, c("philipinnes|phillippines", "america|^us$"), c("philippines", "usa"))) %>% 
  # Add categorization into US or Asia or Europe
  mutate(Region = case_when(
    Response %in% tolower(state.name) ~ "USA",
    Response %in% c("suburban, mid west", "east coast", "west coast") ~ "USA",
    str_detect(Response, "(?:^|\\W)california(?:$|\\W)") ~ "USA", # if USA or <other>, defaults to US
    str_detect(Response, "(?:^|\\W)usa(?:$|\\W)") ~ "USA", # if USA or <other>, defaults to US
    str_detect(Response,"(?:^|\\W)canada(?:$|\\W)") ~ "Canada",
    str_detect(Response, "(?<!\\w)asia(?!\\w)") ~ "Asia",
    TRUE ~ NA
  )) %>%
  mutate(CountryContinent = countrycode(sourcevar = Response,
                             origin = "country.name",
                             destination = "continent")) %>%
  cbind(CityCountry = world.cities[match(n1b_grewup$Response, tolower(world.cities$name)), ][[2]]) %>%
  
  mutate(Response_Cat = coalesce(coalesce(Region, CountryContinent), CityCountry), .after=Response) %>%
  mutate(across(where(is.character), as.factor))

# Check for NAs (uncategorized)
# n1b_grewup %>% filter(is.na(Region) & is.na(CountryContinent) & is.na(CityCountry) )
# n1b_grewup %>% filter(is.na(Response_Cat) )

# Check summary
summary(n1b_grewup)

# Check categorization
n1b_grewup %>% filter(Response_Cat == "USA") %>% count(Response_Cat, Response, sort=TRUE)
n1b_grewup %>% filter(Response_Cat == "Asia") %>% count(Response_Cat, Response, sort=TRUE)
n1b_grewup %>% filter(!(Response_Cat == "USA" | Response_Cat == "Asia")) %>% count(Response_Cat, Response, sort=TRUE)

```
```{r}
# Check data overall
# Specific Labels
n1b_grewup %>% count(Response_Cat, Response, sort=TRUE) %>% add_count(name="n_unique")
n1b_grewup %>% count(Condition, Response_Cat, Response, sort=TRUE) %>% pivot_wider(names_from=Condition, values_from = n)

# Categorized Labels
n1b_grewup %>% count(Response_Cat, sort=TRUE) %>% add_count(name="n_unique")
n1b_grewup %>% count(Condition, Response_Cat, sort=TRUE) %>% pivot_wider(names_from=Condition, values_from = n)
```
All personae categories sometimes identified as USA

msWhite only USA (or Canada), Europe
msAsian and ethAsian only USA (or Canada) or Asian. More msAsian = USA, and more ethAsian = Asia

```{r}
# Check Location category of photos per condition

n1b_grewup %>% filter(Condition=="msWhite") %>% count(Image, Response_Cat, sort=TRUE) %>% pivot_wider(names_from=Response_Cat, values_from = n)

n1b_grewup %>% filter(Condition=="msAsian") %>% count(Image, Response_Cat, sort=TRUE) %>% pivot_wider(names_from=Response_Cat, values_from = n)

n1b_grewup %>% filter(Condition=="ethAsian") %>% count(Image, Response_Cat, sort=TRUE) %>% pivot_wider(names_from=Response_Cat, values_from = n)
```

**Review Comments:**
msWhite photos were all identified as growing up in USA (or Canada) at least once (only other responses were Europe [n=2]; none were Asia).

msAsian photos were all identified as growing up in USA (or Canada) at least once, while some were also identified as from Asia (none were Europe)

ethAsian photos were variably identified as growing up in the USA or Asia (none were Europe)

**Selection Criteria:**
- msAsian must be at least identified as USA (TO CONSIDER: Mostly, select those ONLY USA because including Asia could bleed into ethAsian category, but this might depend more on the ratings)
- ethAsian must be identified as USA + Asia (not ONLY Asia, b/c that would be Asia-Asian; not ONLY USA, because that would be too msAsian)

### (+) Ethnicity
```{r}
n1b_ethnicity <-
  n1b_responses_selected %>% filter(Question=="Ethnicity") %>% select(-Question_Part) %>%
  # text cleaning
  mutate(Response = tolower(str_trim(Response))) %>%
  mutate(Response = mgsub(Response, c("china"), c("chinese"))) %>% 

  # Add categorization into race
  mutate(Asian = case_when(
    str_detect(Response, "(?:^|\\W)(asian|chinese|filipino)(?:$|\\W)") ~ "Asian",
    str_detect(Response, "(?:^|\\W)(hong kong|singapore|japan|korean|taiwan|vietnam|thai)") ~ "Asian",
    TRUE ~ NA
  )) %>%
  mutate(White = case_when(
    str_detect(Response, "(?:^|\\W)(white|european|caucasian|anglo|english|finnish|german|irish|italian|scandinavian|scottish)(?:$|\\W)") ~ "White",
    TRUE ~ NA
  )) %>%
  mutate(American = ifelse(str_detect(Response, "(?:^|\\W)american(?:$|\\W)"), "American", NA)) %>%
  # mutate(Other = case_when(
    # str_detect(Response, "(?:^|\\W)(mexi|hispanic)") ~ "Other",
    # str_detect(Response, "(?:^|\\W)(half|and|mixed)(?:$|\\W)") ~ "Mixed",
    # TRUE ~ NA )) %>%
  mutate(Response_Cat = coalesce(coalesce(coalesce(Asian, White), American), "Other"), .after=Response) %>% # if Asian mixed, Asian
  mutate(across(where(is.character), as.factor))
# n1b_ethnicity

# Check for NAs (uncategorized)
n1b_ethnicity %>% filter(is.na(Response_Cat) )

# Check summary
summary(n1b_ethnicity)

# Check categorization
n1b_ethnicity %>% filter(Response_Cat == "Asian") %>% count(Response_Cat, Response, sort=TRUE)
n1b_ethnicity %>% filter(Response_Cat == "White") %>% count(Response_Cat, Response, sort=TRUE)
n1b_ethnicity %>% filter(!(Response_Cat == "Asian" | Response_Cat == "White")) %>% count(Response_Cat, Response, sort=TRUE)
```

```{r}
# Check data overall
# Specific Labels
n1b_ethnicity %>% count(Response_Cat, Response, sort=TRUE) %>% add_count(name="n_unique")
n1b_ethnicity %>% count(Condition, Response_Cat, Response, sort=TRUE) %>% pivot_wider(names_from=Condition, values_from = n)

# Categorized Labels
n1b_ethnicity %>% count(Response_Cat, sort=TRUE) %>% add_count(name="n_unique")
n1b_ethnicity %>% count(Condition, Response_Cat, sort=TRUE) %>% pivot_wider(names_from=Condition, values_from = n)
```

```{r}
# Check Location category of photos per condition
n1b_ethnicity %>% filter(Condition=="msWhite") %>% count(Image, Response_Cat, sort=TRUE) %>% pivot_wider(names_from=Response_Cat, values_from = n)

n1b_ethnicity %>% filter(Condition=="msAsian") %>% count(Image, Response_Cat, sort=TRUE) %>% pivot_wider(names_from=Response_Cat, values_from = n)

n1b_ethnicity %>% filter(Condition=="ethAsian") %>% count(Image, Response_Cat, sort=TRUE) %>% pivot_wider(names_from=Response_Cat, values_from = n)
```
**Review Comments:**
msWhite photos were all identified as White (or American) at least once (Other responses [n=2]).

msAsian photos were all identified as Asian only (exception: one photo also Other = 'hispanic')

ethAsian photos were  all identified as Asian only

**Selection Criteria:**
- msWhite must be identified as White only
- msAsian and ethAsian must be identified as Asian only
  - PLUS: should additional check East vs. Southeast asian representation within msAsian and ethAsian so that it isn't the difference (e.g., Southeast Asian in msAsian but not ethAsian)

To pick photos: Check a specific photo's words
```{r}
n1b_ethnicity %>% filter(Image=="AAW-47") %>% select(Image, Condition, Response_Cat, Response, PROLIFIC_PID)
```

### (+) Speech
```{r}
n1b_speech <- 
  n1b_responses_selected %>% filter(Question=="Speech") %>% select(-Question_Part) %>%
    # text cleaning
  mutate(Response = tolower(str_trim(Response)))  %>%
  # Consider: shorten long statements by extracting the keyword (e.g. straightforward)
# Add categorization into accentedness
  mutate(OtherAccent = case_when(
    str_detect(Response, "(?:^|\\W)((english|southern|mid-western) accent)(?:$|\\W)") ~ "OtherAccent",
    TRUE ~ NA
  )) %>%
  mutate(Accented = case_when(
    str_detect(Response, "(?:^|\\W)(accented|with a(.+\\s)accent|(aapi|hawaiian) accent)(?:$|\\W)") ~ "Accented",
    TRUE ~ NA
  )) %>%
  mutate(Unaccented = case_when(
    str_detect(Response, "(?:^|\\W)(standard|unaccented|without an accent|no accent|(american|canadian) accent)(?:$|\\W)") ~ "Unaccented",
    # str_detect(Response, "(?:^|\\W)((fluent|clear) english)(?:$|\\W)") ~ "Unaccented",
    TRUE ~ NA
  )) %>%

  mutate(Response_Cat = coalesce(coalesce(coalesce(OtherAccent, Unaccented), Accented), "Other"), .after=Response) %>% 
  mutate(across(where(is.character), as.factor))
# n1b_speech

# Check for NAs (uncategorized)
n1b_speech %>% filter(is.na(Response_Cat) ) %>% select(Response:last_col())

# Check summary
summary(n1b_speech)

# Check categorization
n1b_speech %>% filter(Response_Cat == "Unaccented") %>% count(Response_Cat, Response, sort=TRUE)
n1b_speech %>% filter(Response_Cat == "Accented") %>% count(Response_Cat, Response, sort=TRUE)
n1b_speech %>% filter(!(Response_Cat == "Unaccented" | Response_Cat == "Accented")) %>% count(Response_Cat, Response, sort=TRUE)
```

Accentedness:
```{r}
# Check data overall
# Specific Labels
n1b_speech %>% count(Response_Cat, Response, sort=TRUE) %>% add_count(name="n_unique")
n1b_speech %>% count(Condition, Response_Cat, Response, sort=TRUE) %>% pivot_wider(names_from=Condition, values_from = n)

# Categorized Labels
n1b_speech %>% count(Response_Cat, sort=TRUE) %>% add_count(name="n_unique")
n1b_speech %>% count(Condition, Response_Cat, sort=TRUE) %>% pivot_wider(names_from=Condition, values_from = n)
```

```{r}
# Check Location category of photos per condition
n1b_speech %>% filter(Condition=="msWhite") %>% count(Image, Response_Cat, sort=TRUE) %>% pivot_wider(names_from=Response_Cat, values_from = n)

n1b_speech %>% filter(Condition=="msAsian") %>% count(Image, Response_Cat, sort=TRUE) %>% pivot_wider(names_from=Response_Cat, values_from = n)

n1b_speech %>% filter(Condition=="ethAsian") %>% count(Image, Response_Cat, sort=TRUE) %>% pivot_wider(names_from=Response_Cat, values_from = n)
```

#### Styles
```{r}
n1b_speech <- n1b_speech %>%
  # Other styles
  mutate(Style = case_when(
    Response_Cat == "Other" & str_detect(Response, "(?:^|\\W)(softly|soft spoken|quiet|mild|high)") ~ "Delicate",
    Response_Cat == "Other" & str_detect(Response, "(?:^|\\W)(deliberate|formal)") ~ "Reserved",
    Response_Cat == "Other" & str_detect(Response, "(?:^|\\W)(quick|rapid)") ~ "Fast",
    Response_Cat == "Other" & str_detect(Response, "(?:^|\\W)(slow|drawl)") ~ "Slow",
    Response_Cat == "Other" & str_detect(Response, "(?:^|\\W)(straightforward|clear manner)") ~ "Direct",
    TRUE ~ NA
  ))

# Check Styles data
n1b_speech %>% filter(Style == "Delicate") %>% count(Style, Response, sort=TRUE)
n1b_speech %>% filter(Style == "Reserved") %>% count(Style, Response, sort=TRUE)
n1b_speech %>% filter(Style == "Fast") %>% count(Style, Response, sort=TRUE)
n1b_speech %>% filter(Style == "Direct") %>% count(Style, Response, sort=TRUE)


# Categorized Labels
n1b_speech %>% count(Style, sort=TRUE) %>% add_count(name="n_unique")
n1b_speech %>% count(Condition, Style, sort=TRUE) %>% pivot_wider(names_from=Condition, values_from = n)
```



### (+) Ratings
```{r}
n1b_ratings <-
  n1b_responses %>%
  select(PROLIFIC_PID, Question_Number, Question, Question_Part, Condition, Image_Cat, Image, Response) %>%
  filter(Question=="Ratings") %>% select(-Question) %>% mutate(Response =  as.numeric(as.character(Response))) %>%
  # Convert scales and responses to consistent direction
  separate(Question_Number, into=c("Question_Number", "Version"), sep="-") %>%
separate(Question_Number, into=c(NA, "Rating_Group"), sep="\\.") %>% 
  mutate(Rating_Group = case_when(Rating_Group == "8" ~ "Style",
                                  Rating_Group == "9" ~ "Traits",
                                  Rating_Group == "10" ~ "Culture",
                                  TRUE ~ NA)) %>%
  separate(Question_Part, into=c("Left", "Right"), sep=":") %>%
  mutate(Rating_Scale = case_when(Rating_Group == "Style" & Version == "A" ~ Left,
                                  Rating_Group == "Traits" & Version == "A" ~ Right,
                                  Rating_Group == "Culture" & Version == "A" ~ Left,
                                  Rating_Group == "Style" & Version == "B" ~ Right,
                                  Rating_Group == "Traits" & Version == "B" ~ Left,
                                  Rating_Group == "Culture" & Version == "B" ~ Right,
                                  TRUE ~ NA), .before=(Rating_Group))  %>%
  mutate(Rating_Value = case_when(Rating_Group == "Style" & Version == "A" ~ abs((Response)-8),
                                  Rating_Group == "Traits" & Version == "B" ~ abs((Response)-8),
                                  Rating_Group == "Culture" & Version == "A" ~ abs((Response)-8),
                                  TRUE ~ Response), .before=(Response)) %>%
  select(-Version, -Left, -Right) %>% relocate(c(Rating_Group,Rating_Scale), .before=Rating_Value) %>%
  # Add z-score transformed ratings by participant (participant-normalized)
  group_by(PROLIFIC_PID) %>% 
  mutate(Rating_ZScore = scale(Rating_Value, center=TRUE, scale=TRUE), .before=Rating_Value) %>%
  mutate(Response_ZScore = scale(Response, center=TRUE, scale=TRUE)) %>% 
  ungroup() %>%
  mutate(across(where(is.character), as.factor))

summary(n1b_ratings)
n1b_ratings
```
Summary stats
```{r}
# Check summary stats of data overall
n1b_ratings %>% summarize(min=min(Rating_Value), max=max(Rating_Value), mean=mean(Rating_Value), median=median(Rating_Value))
# n1b_ratings %>% summarize(min=min(Rating_ZScore), max=max(Rating_ZScore), mean=mean(Rating_ZScore), median=median(Rating_ZScore))

# by rating group
n1b_ratings %>% group_by(Rating_Group) %>% summarize(min=min(Rating_Value), max=max(Rating_Value), mean=mean(Rating_Value), median=median(Rating_Value))

# by condition
n1b_ratings %>% group_by(Condition, Rating_Group) %>% summarize(min=min(Rating_Value), max=max(Rating_Value), mean=mean(Rating_Value), median=median(Rating_Value))
n1b_ratings %>% group_by(Condition, Rating_Scale) %>% summarize(min=min(Rating_Value), max=max(Rating_Value), mean=mean(Rating_Value), median=median(Rating_Value))
# n1b_ratings %>% group_by(Condition, Rating_Scale) %>% summarize(min=min(Rating_ZScore), max=max(Rating_ZScore), mean=mean(Rating_ZScore), median=median(Rating_ZScore))

# by image
n1b_ratings %>% group_by(Image, Rating_Group) %>% summarize(min=min(Rating_Value), max=max(Rating_Value), mean=mean(Rating_Value), median=median(Rating_Value))
n1b_ratings %>% group_by(Image, Rating_Scale) %>% summarize(min=min(Rating_Value), max=max(Rating_Value), mean=mean(Rating_Value), median=median(Rating_Value))
# n1b_ratings %>% group_by(Image, Rating_Scale) %>% summarize(min=min(Rating_ZScore), max=max(Rating_ZScore), mean=mean(Rating_ZScore), median=median(Rating_ZScore))

```

Means per
```{r}
# Check  category of photos per condition + sd
# Tables
n1b_ratings %>% group_by(Condition, Rating_Group) %>% 
  summarize(mean=mean(Rating_Value), sd=sd(Rating_Value)) %>% 
  mutate(str_mean = sprintf("%.2f", round(mean,2)), str_sd = sprintf("%.2f", round(sd,2))) %>%
  mutate(`Mean (SD)`=paste(str_mean, " (", str_sd, ")")) %>% # <- swap in paste0 for printing
  select(-mean:-str_sd) %>%
  pivot_wider(names_from=Condition, values_from = `Mean (SD)`)
  
n1b_ratings %>% group_by(Condition, Rating_Group, Rating_Scale) %>% 
  summarize(mean=mean(Rating_Value), sd=sd(Rating_Value)) %>% 
  mutate(str_mean = sprintf("%.2f", round(mean,2)), str_sd = sprintf("%.2f", round(sd,2))) %>%
  mutate(`Mean (SD)`=paste(str_mean, " (", str_sd, ")")) %>% # <- swap in paste0 for printing
  select(-mean:-str_sd) %>%
  pivot_wider(names_from=Condition, values_from = `Mean (SD)`)
```



Plot Functions:
```{r}
# Parallel Plot Function
# FUNCTION REF: https://stackoverflow.com/questions/52340768/using-a-custom-function-with-tidyverse 

parallel_plot <- function(df, x, y, group, full_scale=FALSE, angle_axis_labels=FALSE) {
  x = enquo(x)
  y = enquo(y)
  group = enquo(group)
  min_y <- min(df %>% pull(!!y))
  max_y <- max(df %>% pull(!!y))

  plot <-
    df %>% 
    group_by((!!group), (!!x)) %>% 
    
    ggplot(aes(x=(!!x), y=(!!y), color=(!!group), fill=(!!group), group=(!!group)))  +
    stat_summary(fun.data=mean_se, geom="pointrange", position=position_dodge(), alpha=1) +
    stat_summary(fun.data=mean_se, geom="line", position=position_dodge(), alpha=1) +
    scale_color_viridis(option="viridis", discrete=TRUE) + # <- UNCOMMENT to get colorblind-friendly palette
    theme_minimal()
    
  if (full_scale == TRUE){
  plot <- plot + scale_y_continuous(limits = c(min_y, max_y), breaks = seq(floor(min_y), ceiling(max_y), 1)) 
  }
  if (angle_axis_labels == TRUE){
   plot <- plot + theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) + 
  theme(plot.margin = margin(0,0,0,40, unit = "pt"))  # pad left side of plot to read angled labels (t,r,b,l)  
  }
  plot
}

# Violin Plot Function
# FUNCTION REF: https://stackoverflow.com/questions/52340768/using-a-custom-function-with-tidyverse 

violin_plot <- function(df, x, y, group, full_scale=FALSE, angle_axis_labels=FALSE) {
  x = enquo(x)
  y = enquo(y)
  group = enquo(group)
  min_y <- min(df %>% pull(!!y))
  max_y <- max(df %>% pull(!!y))

  plot <-
    df %>% group_by((!!group), (!!x)) %>% 
    ggplot(aes(x=(!!x), y=(!!y), color=(!!group), fill=(!!group)))  +
    geom_violin(alpha=0.5, position=position_dodge(0.95)) +
    geom_boxplot(fill="white", alpha=0.9, width=0.2, position=position_dodge(0.95)) +
    scale_color_viridis(option="viridis", discrete=TRUE) + # <- UNCOMMENT to get colorblind-friendly palette
    scale_fill_viridis(option="viridis", discrete=TRUE) + # <- UNCOMMENT to get colorblind-friendly palette
    theme_minimal()
  
  if (full_scale == TRUE){
  plot <- plot + scale_y_continuous(limits = c(min_y, max_y), breaks = seq(floor(min_y), ceiling(max_y), 1)) 
  }
  if (angle_axis_labels == TRUE){
   plot <- plot + theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) + 
     theme(plot.margin = margin(0,0,0,40, unit = "pt"))  # pad left side of plot to read angled labels (t,r,b,l)  
  }
  plot
}
```


Parallel plots show the differences in score (=y, e.g., rating values) across score type (=x, e.g., rating scales) for each group (=series as represented by color and line, e.g., condition).

#### By Condition

Overview of ratings grouping scales under Rating_Group (Culture, Traits, Style)
```{r}
# Condition Mean Plots by Rating_Group
# Get plots: Zoomed in (Raw and ZScore)
parallel_plot(n1b_ratings, x=Rating_Group, y=Rating_Value, group=Condition)
parallel_plot(n1b_ratings, x=Rating_Group, y=Rating_ZScore, group=Condition)

# Get plots: Zoomed out (Raw and ZScore)
parallel_plot(n1b_ratings, x=Rating_Group, y=Rating_Value, group=Condition, full_scale = TRUE)
parallel_plot(n1b_ratings, x=Rating_Group, y=Rating_ZScore, group=Condition, full_scale = TRUE)
```
```{r}
# Condition Distribution + Median Violin Plots by RatingGroup
violin_plot(n1b_ratings, x=Rating_Group, y=Rating_Value, group=Condition, full_scale = TRUE, angle_axis_labels = TRUE)
```

Overview of all scales shown individually, reordered into helpful viewing order
```{r}
# Condition Mean Parallel Plots by Rating_Scale
# Get plots: Zoomed in (Raw and ZScore)
n1b_ratings_releveled <-
  n1b_ratings %>% 
  # reorder factors  
  mutate(Rating_Scale = fct_relevel(Rating_Scale, 
  "American", "Native speaker of English", "American-accented", "Aligned with American culture",  # Culture
  "Enthusiastic", "Confident", "Friendly", "Likeable", "Attractive", "Intelligent",               # Traits
  "Feminine", "Clear speaker","Casual", "Cool", "Nerdy", "Slow speaker"))                         # Style

parallel_plot(n1b_ratings_releveled, x=Rating_Scale, y=Rating_Value, group=Condition, angle_axis_labels=TRUE) 
parallel_plot(n1b_ratings_releveled, x=Rating_Scale, y=Rating_ZScore, group=Condition, angle_axis_labels=TRUE) 

```
```{r}
# Condition Distribution + Median Violin Plots by Rating_Scale
n1b_ratings_releveled %>% filter(Rating_Group == "Culture") %>%
  violin_plot(x=Rating_Scale, y=Rating_Value, group=Condition, full_scale = TRUE, angle_axis_labels = TRUE) + facet_grid(~Rating_Group)

n1b_ratings_releveled %>% filter(Rating_Group == "Traits") %>%
  violin_plot(x=Rating_Scale, y=Rating_Value, group=Condition, full_scale = TRUE, angle_axis_labels = TRUE) + facet_grid(~Rating_Group)

n1b_ratings_releveled %>% filter(Rating_Group == "Style") %>%
  violin_plot(x=Rating_Scale, y=Rating_Value, group=Condition, full_scale = TRUE, angle_axis_labels = TRUE) + facet_grid(~Rating_Group)
```

#### By Image
```{r}
# Add all images mean plots to find outliers to drop (or matched pairs to keep)

```


```{r}
# Parallel Plot exploration
current_condition = "msWhite"
n1b_ratings_releveled %>% filter(Condition == current_condition) %>%
  parallel_plot(., x=Rating_Scale, y=Rating_Value, group=Image, angle_axis_labels=TRUE) + labs(title=current_condition)

current_condition = "msAsian"
n1b_ratings_releveled %>% filter(Condition == current_condition) %>%
  parallel_plot(., x=Rating_Scale, y=Rating_Value, group=Image, angle_axis_labels=TRUE) + labs(title=current_condition)

current_condition = "ethAsian"
n1b_ratings_releveled %>% filter(Condition == current_condition) %>%
  parallel_plot(., x=Rating_Scale, y=Rating_Value, group=Image, angle_axis_labels=TRUE) + labs(title=current_condition)
```


```{r}
# Add image direct comparision plots


```

### Finalize Scores
Get mean scores per image, to put through a PCA.
```{r}
# By-Image means: Get across-participant means per Rating_Scale for each Image 
n1b_ratings_means <- n1b_ratings_releveled %>% group_by(Condition, Image_Cat, Image, Rating_Group, Rating_Scale) %>%
  summarize(Rating_Value=mean(Rating_Value), Rating_ZScore = mean(Rating_ZScore)) %>% ungroup()

# Get factors as columns
# Raw rating values
n1b_ratings_vars_raw <-
   n1b_ratings_means %>%  pivot_wider(id_cols=Condition:Image, names_from = Rating_Scale, values_from =  Rating_Value)

# Zscores
n1b_ratings_vars_zscore <-
  n1b_ratings_means %>%  pivot_wider(id_cols=Condition:Image, names_from = Rating_Scale, values_from = Rating_ZScore)

# View data
n1b_ratings_means
n1b_ratings_vars_raw
n1b_ratings_vars_zscore
```

Check correlations between measures to assess collinearity.

Function to get correlation info:
```{r, fig.width=8, fig.height=7.5}
get_correlations <- function(df, columns_to_keep){
  # NOTE: Columns to keep cannot be name of column, only indices or function (e.g. last_col())
  corr_matrix <-
    df %>% select(columns_to_keep) %>%
    cor(., method="pearson")  # Alt: method="spearman"
  # # View the correlation matrix
  corr_df <- corr_matrix %>% as_tibble(rownames = "var") # independent variables correlation matrix 
  print(corr_df)
  # # Visualize
  corr_plot <- corrplot(rating_vars_cor,method='number',is.corr = T)
  print(corr_plot)
}
```

Raw rating values:
```{r, fig.width=8, fig.height=7.5}
get_correlations(n1b_ratings_vars_raw, columns_to_keep=4:last_col())
# TBD - Include a correlation scatterplot to visualize specific variables. (see Visualize > Scored Data > Correlation Scatters)
```
The "Culture" Rating_Group, may be highly collinear (>0.8 and >0.9), which will result in a single value. Others are all not highly collinear, though Friendly and Likable are similar (>0.8) as well.

ZScored rating values:
```{r, fig.width=8, fig.height=7.5}
get_correlations(n1b_ratings_vars_zscore, columns_to_keep=4:last_col())
# TBD - Include a correlation scatterplot to visualize specific variables. (see Visualize > Scored Data > Correlation Scatters)
```

The "Culture" Rating_Group, may be highly collinear (>0.8 and >0.9), which will result in a single value. Others are all not highly collinear.

## Analyze 1
#### Run PCA
Notes for PCA Interpretation
```{r}
#############################################
## (1) Checking the number of dimensions

# Parallel Analysis
# Standard way to decide on the number of factors or components needed in an FA or PCA.

# Eigenvalues & percent variance accounted for
# One guideline is to only include dimensions that have an eigenvalue of at least 1, but note that...
# This guideline only applies if using correlation matrix (i.e. scaled units; scale.unit = T)
# Because we don't want a factor that accounts for less than what a single variable accounts for (single variable=1)

# Scree Plot
# One guideline is to check starting with the "elbow" value, plus or minus 1
# Check for where there is an "elbow" where the plot bends, such that subsequent factors don't contribute much

## (2) Interpreting the output factor values

# Factor matrix (raw eigenvectors = the factor score coefficients; sometimes called the factor, but not factor scores)
# To interpret, focus on the most extreme factor values (or loadings, below)
# Higher values means that those variables contribute more to the specific dimension/component/factor
# Dimensions/components/factors can be interpreted based on which variables contribute more

# Factor loadings (eigenvectors scaled by the square root of their associated eigenvalues)
# Provide similar information about which variables contribute to each dimension/component/factor, but also
# Can be interpreted as correlations between each variable and the factor
# One guideline treats all values less than 0.3 as 0, thus drops them from consideration (irrelevant for that factor) 

# Rotated factor matrix
# Orthogonally rotates factor matrix for ease of interpretation of each dimension

#############################################
## (3) Checking the individual coordinate scores
# Individual coordinate scores (principle coordinates)
# Same as factor scores for each subject and dimension (weighted sum of all of a subjects raw scores, where the weights are the eigenvector values)
# i.e. values are calculated from the normalized variable scores (Z-scores) multiplied by the eigenvector weights, then summed
```

##### Select Data
Select data for PCA.
```{r}
# Use Zscores to represent responses without participant bias in scale range 
#   (e.g., never selecting 1 means their lowest value is represented by 2, but their 2 can be equated to another person's 1)
# Use Raw scores to represent responses as representing true value 
#   (e.g., never selecting 1 means the true perceptual range represented by the photos never goes down to 1 for this person, and their 1 is equated to another person's 1)

current_source_data <- n1b_ratings_vars_zscore # Alt: n1b_ratings_vars_raw

## Maximal set
image_vars_pca <- current_source_data %>% select(-Condition:-Image)
image_vars_pca
```

##### Process PCA
Determine number of components via Parallel analysis.
```{r }
## Relevant libraries
# `PCA` command from `FactoMineR` library (see index for more info)
# `paran` command from `paran` library
# `Varimax` command from `GPArotations` library (https://stats.stackexchange.com/questions/59213/how-to-compute-varimax-rotated-principal-components-in-r)

## (1) Run Parallel Analysis with `paran`
# Standard way to decide on the number of factors or components needed in an FA or PCA.
# Prints out a scree plot as well, with the randomized line + unadjusted line
paran(image_vars_pca,
      graph = TRUE, color = TRUE, 
      col = c("black", "red", "blue"), lty = c(1, 2, 3), lwd = 1, legend = TRUE, 
      file = "", width = 640, height = 640, grdevice = "png", seed = 0)
```
Parallel analysis suggests 2 components retained.
Scree plots suggest ~3 components, based on the location of the elbow. Could try 2, 3, or 4 components.
Eigenvalues suggest 2 components, as only the first two comps have a value above 1.
The _difference in_ eigenvalues suggests 3 components, as up to the third comp has a difference greater than 1. (See: https://stats.stackexchange.com/questions/450752/understanding-how-many-components-to-include-for-pca)
Interpretability indicates 3 components, such that FrCA serves as its own component (Dim3).

```{r}
## (2) Run PCA with `FactoMineR`
# ncp = number of components; adjust after checking the parallel analysis output

# FactoMineR PCA Commands
#score_PCA        # lists commands
#score_PCA$var    # variables
#score_PCA$ind    # individuals
#score_PCA$call   # summary stats

# Conduct PCA with scaling/standardizing
score_PCA <- PCA(image_vars_pca, scale.unit = T, ncp =2, graph=T)

## Relevant Raw PCA Output
# Eigenvalues & percent variance accounted for
eigenvalues <- score_PCA$eig
as_tibble(eigenvalues, rownames="components")

# Eigenvectors (=Factor matrix, factor score coefficients, principal directions, principal axes; sometimes called the factor, but NOT factor scores; these are called loadings by some but its incorrect).
eigenvectors <- score_PCA$var$coord
as_tibble(eigenvectors, rownames="Score")

# Factor scores for each subject and dimension (also: Individual coordinate scores; principle coordinates)
rawScores <- score_PCA$ind$coord
as_tibble(rawScores, rownames="Item")

# Factor loadings (=loadings, correlation loadings, or scaled factor coefficients; eigenvectors scaled by the square root of their associated eigenvalues)
# Calculate factor loadings using the output eigenvectors and eigenvalues (i.e. divide each eigenvector column value by the appropriate eigenvalue square root).
rawLoadings <- sweep(eigenvectors,MARGIN=2,STATS=sqrt(eigenvalues[1:ncol(eigenvectors),1]),FUN="/") # margin 1=rows, 2=cols
as_tibble(rawLoadings, rownames="Score")
```




```{r lbqdata-pca2-3}
## (3) Conduct rotation on the PCA factor loadings with `GPArotation`
# Rotations are typically done on the retained component factor loadings, not on all components nor on the eigenvectors
# Performed for ease of interpretation, maximizing factor loadings
rotLoadings <- Varimax(rawLoadings, normalize=T)$loadings
as_tibble(rotLoadings, rownames="Score") 

# Recover Rotation matrix from loadings
# Because the rotLoadings are calculated from rawLoadings %*% rotMatrix, can recover rotMatrix by rotLoadings "divided" by rawLoadings, which in matrix multiplication is multiplying by the inverse (transpose) 
# Note: For some reason, can't call Varimax(rawLoadings)$rotmat (just get NULL); this recreates the same matrix from Varimax(rawLoadings)
rotMatrixL <- t(rawLoadings) %*% rotLoadings
as_tibble(rotMatrixL, rownames="Dimensions")

# Calculate rotated factor scores
# The formula simply multiplies the normalized variable scores with the rotation matrix to get rotated factor scores
# First, z-score the raw scores using base R scale()
# Then, matrix multiply the matrix of zScores with the rotation matrix
# Result is a matrix with columns=components and rows=each subject
zScores <- scale(rawScores)
rotScores <- zScores %*% rotMatrixL
as_tibble(rotScores, rownames="Item")

```

```{r}
# For comparison, a different rotation function. Requires normalization. Still a little different but similar enough. Provides rotmat and SS loadings. 
## Rotate eigenvectors (not typical, according to Stats notes and StackExchange, but reasonable-looking SS loadings+% variance)
# stats::varimax(eigenvectors)
## Rotate factor loadings (typical, but unreasonable(?)-looking SS loadings+% variance)
stats::varimax(rawLoadings)
```

##### Factor Loadings
```{r}
# Replace all factor loading values under |0.3| with 0 for better readability

# Raw Loadings
as_tibble(rawLoadings, rownames="Variable") %>% 
  mutate(across(where(is.numeric), ~ ifelse(abs(.x)<0.3, 0, .x)))

# Rotated Loadings
as_tibble(rotLoadings, rownames="Variable") %>% 
  mutate(across(where(is.numeric), ~ ifelse(abs(.x)<0.3, 0, .x)))
```

##### PCA: Raw Plots
```{r lbqdata-pca2-4, echo=F}
## (4) Data Visualization of Raw Scores with `factoextra`

# Plot individual factor scores
fviz_pca_ind(score_PCA, col.ind = "#00AFBB", repel = TRUE)

# Biplot, including individual scores and factor vectors
fviz_pca_biplot(score_PCA, label = "all", col.ind = "#00AFBB", col.var="black", ggtheme = theme_minimal())
```

##### PCA: Rotated Plots
```{r plbqdata-pca2-5, echo=F}
## (5) Manual Plots of Rotated Scores with `ggplot`

## Create dataframes of the rotated factor loading and factor score matrices

# Convert rotated factor loadings matrix to data frame; add variable number
rotLoadingsData <- as.data.frame(rotLoadings)
rotLoadingsData <- mutate(rotLoadingsData, variable = row.names(rotLoadings))
rotLoadingsData <- mutate(rotLoadingsData, variable = factor(variable))
#rotLoadingsData

# Convert rotated factor score matrix to data frame; add subject number
rotScoreData <- as.data.frame(rotScores)
rotScoreData <- mutate(rotScoreData, subject = 1:n())
rotScoreData

## Create base plots
# Loading plot
loadingplot <- ggplot(rotLoadingsData, aes(x=Dim.1, y=Dim.2))+
  geom_segment(data=rotLoadingsData, mapping=aes(x=0, y=0, xend=Dim.1*4, yend=Dim.2*4), arrow=arrow(), size=0.5, color="black") +
  geom_text(data=rotLoadingsData, aes(x=Dim.1*4, y=Dim.2*4, label=variable), color="red",check_overlap=T) +
  scale_x_continuous(lim=c(-2.5, 2.5),breaks=seq(-3,3,1)) +
  scale_y_continuous(lim=c(-2, 3),breaks=seq(-3,3,1)) +
  geom_hline(yintercept=0, linetype="dashed") +
  geom_vline(xintercept=0, linetype="dashed") +
  labs(title="Variables - PCA", x="Dim 1", y="Dim 2") +
  theme_minimal()+
  theme(plot.title=element_text(size=15),
        plot.subtitle=element_text(size=15, face="italic"),
        axis.title=element_text(size=15),
        axis.text=element_text(size=14),
        strip.background =element_rect(fill="white"),
        strip.text = element_text(size=14))+
  theme(legend.title = element_text(size=16),
        legend.text=element_text(size=14))
loadingplot


# Scatter plot of Individual factor scores
dimplot = ggplot(rotScoreData, aes(x=Dim.1, y=Dim.2))+
  geom_point(na.rm=TRUE, color="#00AFBB") +
  geom_text(aes(label=subject),hjust=1.5,vjust=1.5, color="#00AFBB", check_overlap=T)+
  scale_x_continuous(lim=c(-2.5, 2.5),breaks=seq(-3,3,1)) +
  scale_y_continuous(lim=c(-3.5, 3.5),breaks=seq(-3,3,1)) +
  geom_hline(yintercept=0, linetype="dashed") +
  geom_vline(xintercept=0, linetype="dashed") +
  labs(title="Individuals - PCA", x="Dim 1", y="Dim 2") +
  theme_minimal()+
  theme(plot.title=element_text(size=15),
        plot.subtitle=element_text(size=15, face="italic"),
        axis.title=element_text(size=15),
        axis.text=element_text(size=14),
        strip.background =element_rect(fill="white"),
        strip.text = element_text(size=14))+
  theme(legend.title = element_text(size=16),
        legend.text=element_text(size=14))
dimplot

## Merge loading and score plot = Biplot

# Biplot of factor loadings + ind factor scores
ggplot(rotScoreData, aes(x=Dim.1, y=Dim.2))+
  geom_point(na.rm=TRUE, color="#00AFBB") +
  geom_text(aes(label=subject),hjust=1.5,vjust=1.5, color="#00AFBB", check_overlap=T)+
  
  # Overlay loading plot (i.e. arrows)
  geom_segment(data=rotLoadingsData, mapping=aes(x=0, y=0, xend=Dim.1*4, yend=Dim.2*4), arrow=arrow(), size=0.5, color="black") +
  geom_text(data=rotLoadingsData, aes(x=Dim.1*4.5, y=Dim.2*4.5, label=variable), color="red",check_overlap=T, nudge_y = 0)+

  scale_x_continuous(lim=c(-3.5, 3.5),breaks=seq(-3,3,1)) +
  scale_y_continuous(lim=c(-4.5, 4.5),breaks=seq(-3,3,1)) +
  geom_hline(yintercept=0, linetype="dashed") +
  geom_vline(xintercept=0, linetype="dashed") +
  labs(title="Biplot - PCA", x="Dim 1", y="Dim 2") +
  theme_minimal()+
  theme(plot.title=element_text(size=15),
        plot.subtitle=element_text(size=15, face="italic"),
        axis.title=element_text(size=15),
        axis.text=element_text(size=14),
        strip.background =element_rect(fill="white"),
        strip.text = element_text(size=14))+
  theme(legend.title = element_text(size=16),
        legend.text=element_text(size=14))


```
NOTE: Both ZScore rotated and unrotated are very similar (for pilot data; however, big difference for Raw ratings)

The results of the Zscore rotated PCA with three components retained suggest that:
* Dim1 is the "culture" or "American" component, with all four of those American-related ratings being highly correlated.

* Dim2 is the "social attractiveness" or "likeability" component, linked to positive traits like Attractive, Likeable (strongest), Friendly, Confident, and Enthusiastic (when rotated), as well as confidence-related stylistic features like Cool and Fast speaker (i.e., non-Slow speaker)

* The other features that act more like their factors rather than a grouped/similar/collinear unit are:
  * Intelligent
  * Nerdy (vs Enthusiastic, when not rotated)
  * Casual
  * Feminine — definitely seems more like a third dimension
  

Based on the biplots, where is the best slice to take matched participants from? 
* Since Dim1 is the relevant distinguishing component, we'd want to take different personae across this dimension — i.e., this should differ significantly across Personae conditions (ethAsian vs. msAsian / msWhite)
* Since Dim2 (and others) are the "flavor" non-target characteristics to ensure social perceptual similarity on, those should be similar, maybe towards the mean around 0 (i.e., visually, along the horizontal x axis line is where we should pick from).

In addition, use the Ethnicity, GrewUp, and Speech scores to screen for outliers or non-matching aspects. So, we don't want to include even if they might match in ratings but: 
* e.g., differ in being East Asian vs. Southeast Asian or 
* e.g., differ in where they are from like always California vs. never California

##### Finalize Data
```{r}
# Merge PCA factor scores back to image number and raw scores
n1b_ratings_vars_pca <-
  n1b_ratings_vars_zscore %>%
  cbind(
    as_tibble(rotScores, rownames="Item"), . # alternatively rawScores
  ) %>%
relocate(Condition:Image,
       Dim1_American=Dim.1, Dim2_Likeable=Dim.2
       ) %>% select(-Item)
n1b_ratings_vars_pca
```

```{r}
# Summary stats of each PC/Dimension
quick_summarize <- function(df, col){
  col = enquo(col)
  df %>%  summarize(across(!!col, list(mean=mean, sd=sd, min=min, max=max, median=median)))
}

quick_summarize(n1b_ratings_vars_pca, Dim1_American)
quick_summarize(n1b_ratings_vars_pca, Dim2_Likeable)

```

##### Visualize Data
Function for labelled scatterplot of variables
```{r}
labeled_scatterplot <- function(df, x, y, label, group, show_points=TRUE, full_scale=FALSE, angle_axis_labels=FALSE) {
  x = enquo(x)
  y = enquo(y)
  label = enquo(label)
  group = enquo(group)
  min_y <- min(df %>% pull(!!y))
  max_y <- max(df %>% pull(!!y))

  plot <- df %>% group_by((!!group), (!!x)) %>% 
    ggplot(aes(x=(!!x), y=(!!y), color=(!!group), fill=(!!group), label=(!!label)))
  if (show_points == TRUE){
    plot <- plot + geom_point(alpha=0.7)
  }
  plot <- plot +
    geom_text(alpha=0.9, nudge_x = 0.2, nudge_y = 0.2) +
    scale_color_viridis(option="viridis", discrete=TRUE) + # <- UNCOMMENT to get colorblind-friendly palette
    scale_fill_viridis(option="viridis", discrete=TRUE) + # <- UNCOMMENT to get colorblind-friendly palette
    gg_theme() + theme_minimal()
  
  if (full_scale == TRUE){
  plot <- plot + scale_y_continuous(limits = c(min_y, max_y), breaks = seq(floor(min_y), ceiling(max_y), 1)) 
  }
  if (angle_axis_labels == TRUE){
   plot <- plot + theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) + 
     theme(plot.margin = margin(0,0,0,40, unit = "pt"))  # pad left side of plot to read angled labels (t,r,b,l)  
  }
  plot
}
```

```{r}
# Get variable names
colnames(n1b_ratings_vars_pca)

# Double check raw zscore correlations for select variables
n1b_ratings_vars_pca %>% filter(Condition=="ethAsian") %>%
  ggplot(aes(y=American, x=`American-accented`)) +  geom_point() + geom_smooth(method="lm") + theme_minimal()

n1b_ratings_vars_pca %>% filter(Condition=="msAsian") %>%
  ggplot(aes(y=American, x=Likeable)) +  geom_point() + geom_smooth(method="lm") + theme_minimal()
```


```{r}
# Double check PCA correlations
n1b_ratings_vars_pca %>%
  ggplot() +
  # facet_wrap(~Image) +
  geom_point(aes(y=Dim1_American, x=American)) +
  geom_point(aes(y=Dim1_American, x=`Native speaker of English`), col="blue", alpha=0.7) +
  geom_point(aes(y=Dim1_American, x=`American-accented`), col="red", alpha=0.7) +
  geom_point(aes(y=Dim1_American, x=`Aligned with American culture`), col="orange", alpha=0.7) +
  theme_minimal()

```

Get plot of main Dimensions with the labelled images to review the selections below
```{r}
# Main Dimensions
# Specific Images colored by Condition
n1b_ratings_vars_pca %>% labeled_scatterplot(x=Dim1_American, y=Dim2_Likeable, label=Image, group=Condition, show_points=FALSE)
```
```{r}
# Other
# Specific Images colored by Condition
# n1b_ratings_vars_pca %>% labeled_scatterplot(x=Dim1_American, y=Feminine, label=Image, group=Condition, show_points=FALSE)
# n1b_ratings_vars_pca %>% labeled_scatterplot(x=Dim1_American, y=Intelligent, label=Image, group=Condition, show_points=FALSE)
```

## Assess

### Find Outliers
Consider: Check for Outliers with Mahalanobis distances

* Use the Mahalanobis distance to assess outliers/matches via visual inspection and selecting a threshold cut-off

```{r}
# Get mahalnobis distances Function
get_mdist <- function(scores_df, index_df){
  # Finding the center point 
center  = colMeans(scores_df)
# Finding the covariance matrix
cov     = cov(scores_df)
# Calculate Mahalnobis distance + identify outliers
mdist_df <- index_df %>% 
  cbind(m_dist = mahalanobis(scores_df, center, cov))  %>%
  mutate(outlier = ifelse(m_dist > 10, TRUE, FALSE))
  # mutate(pvalue = pchisq(m_dist, df=3, lower.tail=FALSE)) #pval<0.001 outlier
return(mdist_df)
}
```

```{r}
# All orthogonal/unique variables
scores_df <- n1b_ratings_vars_pca %>% select(-Condition:-Image) %>% 
  select(Dim1_American, Dim2_Likeable, Feminine, Casual, Intelligent, Nerdy, `Clear speaker`)
index_df <- n1b_ratings_vars_pca %>% select(Condition:Image)

# Get mahalnobis distances
mdist_df <- get_mdist(scores_df, index_df)

# Most different considering all variables
# See results
mdist_df %>% arrange(desc(m_dist))
# Get list of potential outliers to check
mdist_df %>% filter(outlier==TRUE) %>% select(Condition, Image, m_dist) %>% inner_join(n1b_ratings_vars_pca) %>% select(-Image_Cat)
```

```{r}
# All orthogonal/unique variables, excluding American
scores_df <- n1b_ratings_vars_pca %>% select(-Condition:-Image) %>% 
  select(Dim2_Likeable, Feminine, Casual, Intelligent, Nerdy, `Clear speaker`)
index_df <- n1b_ratings_vars_pca %>% select(Condition:Image)

# Get mahalnobis distances
mdist_df <- get_mdist(scores_df, index_df)


# Most similar (across conditions) excluding American
# See results
mdist_df %>% arrange((m_dist))
# Get list of potential matches to check
mdist_ranks <- mdist_df %>% select(Condition, Image, m_dist) %>% inner_join(n1b_ratings_vars_pca) %>% select(-Image_Cat) %>% 
  arrange((m_dist)) %>% group_by(Condition) %>%
  mutate(ingroup_ranks = order(order(m_dist, decreasing=FALSE)), .after=m_dist) #%>% arrange(ingroup_ranks)
# TODO: pivot to matched rank columns, image value for condition based on rank
mdist_ranks %>%  pivot_wider(id_cols = ingroup_ranks, names_from = Condition, values_from = c(Image, m_dist))
```

### Get Narrowed Conditions

TODO:
- Pull in screener categories; filter out
- How to get most similar rows across categories? Mahalanobis but smallest values
  - TODO: Try with fewer unique cols, just the most relevant/orthogonal seeming, like feminine, casual and intelligent? 

Select 4-5 photos 
* Based on Dim1 and Dim2 scores
* Based on outliers (mahalanobis scores)
 
### Examine Distinctiveness / Test Differences
Function to get linear model output and pairwise comparisons
```{r}
# LM Output Comparisons Function
# **Reference Code:** 
# - https://cran.r-project.org/web/packages/emmeans/vignettes/comparisons.html 
# - https://broom.tidymodels.org/reference/tidy.summary_emm.html 

lm_emms_pairs <- function(df, formula){
  # run linear model
  lm_out <- lm(formula, data=df)
  print( summary(lm_out) )
  print( lm_df <- tidy(lm_out) )
  
  # get marginal averages (estimated marginal means / Least-squares means)
  emms <- emmeans(lm_out, "Condition")
  print( emms_df <- tidy(emms, conf.int = TRUE) )
  
  # get contrasts
  # (?) tidy(contrast(emms)) # contrast from grand mean(?)
  # pwcs = contrast between paired groups; equivalent to: contrast(emms, method="pairwise") 
  #   +  bonferroni adjusted for multiple comparisons
  pwcs <- tidy(pairs(emms)) %>% mutate(bfrn.adj.p.value = tidy(pairs(emms, adjust="bonferroni")) %>% pull(adj.p.value))
  print(pwcs)
  
  # get effect sizes
  print( tidy(eff_size(emms, sigma = sigma(lm_out), edf = Inf)) )
  
  # plot confidence intervals
  #Option 1
  print( plot(emms, comparisons = TRUE))
  #Option 2
  confint_plot <- ggplot(emms_df, aes(Condition, estimate)) +
    geom_point() + geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width=0.5) + gg_theme()
  print( confint_plot )
}

# Output:
# (1) LM summary, (2) tidy LM, (3) EMMs w/ CIs, (4) Pairwise comp, (5) Effect sizes*, (6) EMM comp plot, (7) EMM CI plot
# (*) not currently sure about the `edf` parameter, currently speifying Inf, narrowing confint unrealistically
```

#### American
Good, Dim1_American scores are different across the three conditions
```{r}
# (1) LM summary, (2) tidy LM, (3) EMMs w/ CIs, (4) Pairwise comp, (5) Effect sizes*, (6) EMM comp plot, (7) EMM CI plot
lm_emms_pairs(n1b_ratings_vars_pca, Dim1_American ~ Condition)
```
#### Likeable
Good, Dim2_Likeable are NOT different across conditions
```{r}
# (1) LM summary, (2) tidy LM, (3) EMMs w/ CIs, (4) Pairwise comp, (5) Effect sizes*, (6) EMM comp plot, (7) EMM CI plot
lm_emms_pairs(n1b_ratings_vars_pca, Dim2_Likeable ~ Condition)
```
#### Feminine
```{r}
# (1) LM summary, (2) tidy LM, (3) EMMs w/ CIs, (4) Pairwise comp, (5) Effect sizes*, (6) EMM comp plot, (7) EMM CI plot
lm_emms_pairs(n1b_ratings_vars_pca, Feminine ~ Condition)
```
#### Nerdy
```{r}
# (1) LM summary, (2) tidy LM, (3) EMMs w/ CIs, (4) Pairwise comp, (5) Effect sizes*, (6) EMM comp plot, (7) EMM CI plot
lm_emms_pairs(n1b_ratings_vars_pca, Nerdy ~ Condition)
```
#### Casual
```{r}
# (1) LM summary, (2) tidy LM, (3) EMMs w/ CIs, (4) Pairwise comp, (5) Effect sizes*, (6) EMM comp plot, (7) EMM CI plot
lm_emms_pairs(n1b_ratings_vars_pca, Casual ~ Condition)
```
#### Clear speaker
```{r}
# (1) LM summary, (2) tidy LM, (3) EMMs w/ CIs, (4) Pairwise comp, (5) Effect sizes*, (6) EMM comp plot, (7) EMM CI plot
lm_emms_pairs(n1b_ratings_vars_pca, `Clear speaker` ~ Condition)
```

# .
# REF: Previous Analysis 
NOTE: This is data specific—Reference the old code below only if needed.

Summarize the relevant response data. Key question is which photos are most often selected for the important descriptors. Here, I sum the total times an image was selected for a particular descriptor, get the proportion of selections per photo per descriptor, and rank the photos by proportion within descriptor. 
```{r}
# Total Responses by Descriptor (general summary)
# n1b_responses_selected %>%
#   group_by(Descriptor_Set, Descriptor) %>%
#   summarize(n_seen=n(), n_select=sum(Response, na.rm=TRUE)) %>%
#   mutate(prop_select=n_select/n_seen) %>%
#   ungroup()

# Total Responses by Descriptor x Image (key)
n1b_props_byImage <- n1b_responses_selected %>%
  group_by(Condition, Image_Cat, Image) %>%
  summarize(n_seen=n(), n_select=sum(Response, na.rm=TRUE)) %>%
  mutate(prop_select=n_select/n_seen) %>%
  ungroup() %>%
  group_by(Descriptor) %>%
  mutate(rank_select = rank(-prop_select, ties.method="min")) %>%
  ungroup()
n1b_props_byImage
```

Select images with only highest-ranking per Descriptor to view.
```{r}
n1b_props_byImage %>%
  group_by(Descriptor) %>%
  arrange(rank_select) %>%
  slice_max(order_by = prop_select, n=10) %>% # If there's more than 10 listed, that's because all those have the exact same proportion as those at or above 10th place.
  filter(Descriptor=="AmAcc")
```
  
#### Image Category
Sanity Check — specifically check AAW vs. WAW photos and AsAm vs. WhAm
```{r}
# Photos — Race
n1b_props_byImage %>% 
  group_by(Image_Cat) %>%
  summarize(mean_prop = mean(prop_select))

# Photos — Race x Descriptor
n1b_props_byImage %>% 
  # Get mean values
  group_by(Image_Cat, Descriptor_Set, Descriptor) %>%
  filter(Descriptor_Set=="Race") %>%
  summarize(mean_prop = mean(prop_select)) %>%
  ungroup() %>%
  # Reshape to wide for easier viewing
  select(-Descriptor_Set) %>%
  pivot_wider(names_from=Descriptor, values_from=mean_prop)
```
## Calculate

**Goal:**
* Identify specific subset (~8~10 per Condition) of top scoring Images (photos, faces) on the relevant dimensions. 
  * --> In the next norming stage, get full ratings to exclude outliers and get 4-8 per Condition. 
  * --> Then, record 8-16 voices --> Norm for ratings to exclude outliers and get ~8~12 voices

**Design**
REGION descriptor = FrCA
ASIAN descriptors = AsAm / ForAcc / EthCul
AMERICAN descriptors = WhAm / AmAcc / AmCul

**Analysis Steps**
1. Raw Proportion Scores (FrCA; AsAm, WhAm; ForAcc, AmAcc, EthCul, AmCul)
  * All positive values
  
2. Relative Proportion Scores (RelAsAm; RelForAcc; RelEthCul)
  * = ASIAN + (-AMERICAN), where positive values mean higher relative ASIAN proportion, negative values mean higher relative AMERICAN proportion, near-zero values mean approx. equal ASIAN-AMERICAN proportions. In other words, AMERICAN proportions were converted to negative (as if the opposite end of a scale) and summed.
  
3. (?) Combined Proportion Scores
  * = RawScore * RelScore, where large positive values = high raw and relative ASIAN proportions, etc. 
  * Alternatively, could just filter by both Raw and Relative Scores

4. Composite Relative Personae Score (RelForEth_Score)
  * RelForAcc + RelEthCul — equally (un)weighted sum, where high positive values mean higher relative ForAcc and EthCul scores indicating strong perception of FOB-like qualities. Negative values mean more Whitewashed-like qualities. Intermediate values mean more bicultural/"regular Asian"-like qualities.

5. (?) Composite Persona Scores (Ethnic_Score, Bicultural_Score, Mainstream_Score)

NOTE: Make sure to check correlations between these different scores to see whether they show the expected differences, or whether some of these considerations are actually a non-issue because of the way the data falls out (i.e., some composite scores are highly correlated to other options.)


Index questions
- settings/switches are binary questions (e.g. Fr)
Polar opposite questions
- PCA

**Analysis Brainstorm:**
* Should I just do an unweighted combination of each (Rel)Score? Or should I run a PCA/factor analysis/Clustering analysis?

<!-- **Analysis Decisions Rationale:** -->
<!-- COMPOSITE PERSONAE SCORING -->
<!-- * What are the relevant dimensions, and in what order or ranking do they place in importance? This will be important to understanding how to pick the photos. -->

<!--   * Where does California/Region play in? Given that it does not factor into the FOB/Asian personae, it should not be an equal contributor. Rather, it should be a screening factor, such that if there are any outliers (e.g. clearly NOT seen as Californian), I remove them. Also, if there is a tie, I could pick the one(s) with a higher OR more consistent/average Californian score. -->

<!--   * Similarly, AsAm/Race could also function as a screener. Although being Asian is an aspect of the FOB/Mainstream persona, it's not as important that they look "more or less" Asian American, as long as it's a reasonably high proportion. If all scores were high, then the one with the highest score would also be high on AsAm; but, importantly, if some score were lower, you wouldn't know which one was lower from a composite value, so it's possible that they are still a good representation of FOB (e.g., lower on AsAm but high on Accent and Culture) OR worse, that they high a high score but are NOT a good representation of FOB (e.g., very high on AsAm, but middling/low on Accent and Culture). -->
      <!-- * Still, I could try to assess a 3-part composite personae score WITH Race and see how that compares. -->

<!--   * Regardless, we know that the important continuous factors are the persona features of (Foreign)Accent and (Ethnic)Culture, and those are two ways of getting at the same thing (i.e., two indicators of FOB/ethnic-oriented persona/identity). So, those can be grouped together, and a continuous joint value representing degree of FOB-persona alignment would be the value to assess. -->

  <!-- * It's interesting too, though, that all the descriptors might be best separate if we view AmAcc and ForAcc to be a strong indicator of localness vs. foreignness. So, if someone is seen as being aligned with ethnic culture but clearly look like they have an AmAcc, then would they be more likely to be considered a strongly "bicultural middle"/"regular or stereotypical Asian" than a FOB? This is actually unclear, as the most canonical "bicultural middle"/"regular or stereotypical Asian" would probably be strongly AmAcc but middling on Culture, showing that they look like they would have access to both cultures. (In contrast, then, someone high on AmAcc AND EthCul would be noncanonical, maybe a bad exemplar of the personae I want.) However, this still shows how Accent might also be considered another level of screening/filtering, where EthCul gives the most information from a gradient perspective, and AmAcc could be considered first. Alternatively, I could use the composite score with AmAcc as a filtering/tie-breaking option (which is similar to using Accent and Culure as separate scores, but is a bit more holistic and doesn't require any hard cut-off ahead of time, since this is a likely highly variable concept that will need interpreting.) -->

<!-- RAW SCORE CALCULAITONS -->
<!-- * For the paired Descriptors, do I need to weight them against each other? e.g., for AsAm and WhAm, do I need to make a combined/weighted/mean/ratio value that will get at people who are (a) high-AsAm + low-WhAm, (b) low AsAm + high-WhAm, (c) high on both, (d) low on both. I don't only care about high values—-I think it's important to consider all combinations because of the one case where they are high on both. If that was the case, I would want to know that, and probably exclude them.  -->
<!--    * I think that means I need a continuum? Convert WhAm selections to negative (-1), then add them together, and if they are high on both OR low on both (or otherwise equivalent on both), they will be near zero, and I wouldn't want to use them. -->
<!--    * for the Culture case, I might WANT to know and use the ones near zero who look like BOTH. And with Accent, it might be that FOBs could be possibly both, and thus near zero. -->

```{r}
#*Factors for comparison:*
#Images
#* Race — AAW vs. WAW

#Descriptors
#* Race — AsAm vs. WhAm
#* Region — FrCA
#* Accent — AmAcc vs. ForAcc
#* Culture — AmCul vs. EthCul

#Aggregate Descriptor Combinations — Persona-Consistent Totals
#* Ethnic — AsAm + ForAcc + EthCul 
#* Bicultural(!Bicultural) — AsAm + AmAcc + EthCul (>=AmCul)
#* Bicultural(!Whitewashed) — AsAm + AmAcc + AmCul
#* Mainstream — WhAm + AmAcc + AmCul
```


#### Descriptor Personae Scoring
Calculate descriptor combination scores.
```{r}
# Descriptor Combinations
n1b_scores_byImage <- n1b_props_byImage %>% 
  # Get mean values
  group_by(Image_Cat, Image, Descriptor) %>% # filter(Descriptor_Set=="Race") %>%
  summarize(mean_prop = mean(prop_select)) %>%
  ungroup() %>%
  # Reshape to one-row-per-image
  pivot_wider(names_from = Descriptor, values_from = mean_prop) %>%
  # Create relative paired variables ## TBD In development
  mutate('RelAsAm' = AsAm + (-WhAm),        # + more AsAm, - more WhAm
         'RelForAcc' = ForAcc + (-AmAcc),   # + more ForAcc, - more WhAm
         'RelEthCul' = EthCul + (-AmCul),    # + more EthCul, - more AmCul
         .after=Image) %>%
  # Calculate unweighted composite/combo scores; without AsAm / WhAm
  mutate(RelForEth_Score = RelForAcc + RelEthCul, #(very pos. = Ethnic-like, very neg. = Mainstream-like)
         Ethnic_Score = ForAcc + EthCul, 
         Bicultural_Score = AmAcc + ((EthCul+AmCul)/2), # include both OR averaged Cul = should be high on both
         Mainstream_Score = AmAcc + AmCul,
         .after=Image) %>%
  relocate(RelForEth_Score, 
           Ethnic_Score, Bicultural_Score, Mainstream_Score,
           RelForAcc, ForAcc, AmAcc,
           RelEthCul, EthCul, AmCul,
           RelAsAm, AsAm, WhAm,
           FrCA,
           .after=Image)
n1b_scores_byImage
```
View and check select scores for my own purposes.
```{r}
n1b_scores_byImage %>%
  select(AsAm, WhAm, RelAsAm)

n1b_scores_byImage %>%
  select(RelForEth_Score, RelForAcc, RelEthCul, ForAcc, EthCul) %>%
  arrange(-RelForEth_Score) 
```

#### Finalize Scores
Check correlations between measures to assess collinearity. 
```{r}
# Create correlation matrix
rating_vars_cor <- 
  n1b_scores_byImage %>% select(-Image_Cat, -Image) %>% 
  # Filter out only factors we want to see visualized for now
  #select(RelForEth_Score, RelForAcc, RelEthCul) %>%
  cor(., method="pearson") #method="spearman")
# View the correlation matrix
rating_vars_cor %>% as_tibble(rownames = "var") # independent variables correlation matrix 

# Visualize
corrplot(rating_vars_cor,method='number',is.corr = T)

# TBD - Include a correlation scatterplot to visualize specific variables. (see Visualize > Scored Data > Correlation Scatters)
```

Group highly correlated measures together, either by dropping one or averaging across. This should be the finalized dataframe/factors to use.
```{r}
#TBD
```


#### Run PCA
Notes for PCA Interpretation
```{r}
#############################################
## (1) Checking the number of dimensions

# Parallel Analysis
# Standard way to decide on the number of factors or components needed in an FA or PCA.

# Eigenvalues & percent variance accounted for
# One guideline is to only include dimensions that have an eigenvalue of at least 1, but note that...
# This guideline only applies if using correlation matrix (i.e. scaled units; scale.unit = T)
# Because we don't want a factor that accounts for less than what a single variable accounts for (single variable=1)

# Scree Plot
# One guideline is to check starting with the "elbow" value, plus or minus 1
# Check for where there is an "elbow" where the plot bends, such that subsequent factors don't contribute much

## (2) Interpreting the output factor values

# Factor matrix (raw eigenvectors = the factor score coefficients; sometimes called the factor, but not factor scores)
# To interpret, focus on the most extreme factor values (or loadings, below)
# Higher values means that those variables contribute more to the specific dimension/component/factor
# Dimensions/components/factors can be interpreted based on which variables contribute more

# Factor loadings (eigenvectors scaled by the square root of their associated eigenvalues)
# Provide similar information about which variables contribute to each dimension/component/factor, but also
# Can be interpreted as correlations between each variable and the factor
# One guideline treats all values less than 0.3 as 0, thus drops them from consideration (irrelevant for that factor) 

# Rotated factor matrix
# Orthogonally rotates factor matrix for ease of interpretation of each dimension

#############################################
## (3) Checking the individual coordinate scores
# Individual coordinate scores (principle coordinates)
# Same as factor scores for each subject and dimension (weighted sum of all of a subjects raw scores, where the weights are the eigenvector values)
# i.e. values are calculated from the normalized variable scores (Z-scores) multiplied by the eigenvector weights, then summed
```

##### Select Data
Select data for PCA.
```{r}
## Maximal set
image_vars_pca <- n1b_scores_byImage %>% select(-Image_Cat, -Image)
image_vars_pca

## Relative set
image_rating_vars_rel <- image_vars_pca %>% select(FrCA, AsAm, WhAm, ForAcc, AmAcc, EthCul, AmCul, 
                                                        RelAsAm, RelForAcc, RelEthCul)
image_rating_vars_rel

## Minimal set
image_rating_vars_raw <- image_vars_pca %>% select(FrCA, AsAm, WhAm, ForAcc, AmAcc, EthCul, AmCul)
image_rating_vars_raw

```

##### Process PCA
Determine number of components via Parallel analysis.
```{r }
## Relevant libraries
# `PCA` command from `FactoMineR` library (see index for more info)
# `paran` command from `paran` library
# `Varimax` command from `GPArotations` library (https://stats.stackexchange.com/questions/59213/how-to-compute-varimax-rotated-principal-components-in-r)

## (1) Run Parallel Analysis with `paran`
# Standard way to decide on the number of factors or components needed in an FA or PCA.
# Prints out a scree plot as well, with the randomized line + unadjusted line
paran(image_rating_vars_raw,
      graph = TRUE, color = TRUE, 
      col = c("black", "red", "blue"), lty = c(1, 2, 3), lwd = 1, legend = TRUE, 
      file = "", width = 640, height = 640, grdevice = "png", seed = 0)
```
Parallel analysis suggests 2 components retained.
Scree plots suggest ~3 components, based on the location of the elbow. Could try 2, 3, or 4 components.
Eigenvalues suggest 2 components, as only the first two comps have a value above 1.
The _difference in_ eigenvalues suggests 3 components, as up to the third comp has a difference greater than 1. (See: https://stats.stackexchange.com/questions/450752/understanding-how-many-components-to-include-for-pca)
Interpretability indicates 3 components, such that FrCA serves as its own component (Dim3).

```{r}
## (2) Run PCA with `FactoMineR`
# ncp = number of components; adjust after checking the parallel analysis output

# FactoMineR PCA Commands
#score_PCA        # lists commands
#score_PCA$var    # variables
#score_PCA$ind    # individuals
#score_PCA$call   # summary stats

# Conduct PCA with scaling/standardizing
score_PCA <- PCA(image_rating_vars_raw, scale.unit = T, ncp =3, graph=T)

## Relevant Raw PCA Output
# Eigenvalues & percent variance accounted for
eigenvalues <- score_PCA$eig
as_tibble(eigenvalues, rownames="components")

# Eigenvectors (=Factor matrix, factor score coefficients, principal directions, principal axes; sometimes called the factor, but NOT factor scores; these are called loadings by some but its incorrect).
eigenvectors <- score_PCA$var$coord
as_tibble(eigenvectors, rownames="Score")

# Factor scores for each subject and dimension (also: Individual coordinate scores; principle coordinates)
rawScores <- score_PCA$ind$coord
as_tibble(rawScores, rownames="Item")

# Factor loadings (=loadings, correlation loadings, or scaled factor coefficients; eigenvectors scaled by the square root of their associated eigenvalues)
# Calculate factor loadings using the output eigenvectors and eigenvalues (i.e. divide each eigenvector column value by the appropriate eigenvalue square root).
rawLoadings <- sweep(eigenvectors,MARGIN=2,STATS=sqrt(eigenvalues[1:ncol(eigenvectors),1]),FUN="/") # margin 1=rows, 2=cols
as_tibble(rawLoadings, rownames="Score")
```




```{r lbqdata-pca2-3}
## (3) Conduct rotation on the PCA factor loadings with `GPArotation`
# Rotations are typically done on the retained component factor loadings, not on all components nor on the eigenvectors
# Performed for ease of interpretation, maximizing factor loadings
rotLoadings <- Varimax(rawLoadings, normalize=T)$loadings
as_tibble(rotLoadings, rownames="Score") 

# Recover Rotation matrix from loadings
# Because the rotLoadings are calculated from rawLoadings %*% rotMatrix, can recover rotMatrix by rotLoadings "divided" by rawLoadings, which in matrix multiplication is multiplying by the inverse (transpose) 
# Note: For some reason, can't call Varimax(rawLoadings)$rotmat (just get NULL); this recreates the same matrix from Varimax(rawLoadings)
rotMatrixL <- t(rawLoadings) %*% rotLoadings
as_tibble(rotMatrixL, rownames="Dimensions")

# Calculate rotated factor scores
# The formula simply multiplies the normalized variable scores with the rotation matrix to get rotated factor scores
# First, z-score the raw scores using base R scale()
# Then, matrix multiply the matrix of zScores with the rotation matrix
# Result is a matrix with columns=components and rows=each subject
zScores <- scale(rawScores)
rotScores <- zScores %*% rotMatrixL
as_tibble(rotScores, rownames="Item")

```

```{r}
# For comparison, a different rotation function. Requires normalization. Still a little different but similar enough. Provides rotmat and SS loadings. 
## Rotate eigenvectors (not typical, according to Stats notes and StackExchange, but reasonable-looking SS loadings+% variance)
# stats::varimax(eigenvectors)
## Rotate factor loadings (typical, but unreasonable(?)-looking SS loadings+% variance)
stats::varimax(rawLoadings)
```

##### Factor Loadings
```{r}
# Replace all factor loading values under |0.4| with 0 for better readability

# Raw Loadings
as_tibble(rawLoadings, rownames="Variable") %>% 
  mutate(across(where(is.numeric), ~ ifelse(abs(.x)<0.4, 0, .x)))

# Rotated Loadings
as_tibble(rotLoadings, rownames="Variable") %>% 
  mutate(across(where(is.numeric), ~ ifelse(abs(.x)<0.4, 0, .x)))
```

##### PCA: Raw Plots
```{r lbqdata-pca2-4, echo=F}
## (4) Data Visualization of Raw Scores with `factoextra`

# Plot individual factor scores
fviz_pca_ind(score_PCA, col.ind = "#00AFBB", repel = TRUE)

# Biplot, including individual scores and factor vectors
fviz_pca_biplot(score_PCA, label = "all", col.ind = "#00AFBB", col.var="black", ggtheme = theme_minimal())
```

##### PCA: Rotated Plots
```{r plbqdata-pca2-5, echo=F}
## (5) Manual Plots of Rotated Scores with `ggplot`

## Create dataframes of the rotated factor loading and factor score matrices

# Convert rotated factor loadings matrix to data frame; add variable number
rotLoadingsData <- as.data.frame(rotLoadings)
rotLoadingsData <- mutate(rotLoadingsData, variable = row.names(rotLoadings))
rotLoadingsData <- mutate(rotLoadingsData, variable = factor(variable))
#rotLoadingsData

# Convert rotated factor score matrix to data frame; add subject number
rotScoreData <- as.data.frame(rotScores)
rotScoreData <- mutate(rotScoreData, subject = 1:72)
rotScoreData

## Create base plots
# Loading plot
loadingplot <- ggplot(rotLoadingsData, aes(x=Dim.1, y=Dim.2))+
  geom_segment(data=rotLoadingsData, mapping=aes(x=0, y=0, xend=Dim.1*4, yend=Dim.2*4), arrow=arrow(), size=0.5, color="black") +
  geom_text(data=rotLoadingsData, aes(x=Dim.1*4, y=Dim.2*4, label=variable), color="red",check_overlap=T) +
  scale_x_continuous(lim=c(-2.5, 2.5),breaks=seq(-3,3,1)) +
  scale_y_continuous(lim=c(-2, 3),breaks=seq(-3,3,1)) +
  geom_hline(yintercept=0, linetype="dashed") +
  geom_vline(xintercept=0, linetype="dashed") +
  labs(title="Variables - PCA", x="Dim 1", y="Dim 2") +
  theme_minimal()+
  theme(plot.title=element_text(size=15),
        plot.subtitle=element_text(size=15, face="italic"),
        axis.title=element_text(size=15),
        axis.text=element_text(size=14),
        strip.background =element_rect(fill="white"),
        strip.text = element_text(size=14))+
  theme(legend.title = element_text(size=16),
        legend.text=element_text(size=14))
loadingplot


# Scatter plot of Individual factor scores
dimplot = ggplot(rotScoreData, aes(x=Dim.1, y=Dim.2))+
  geom_point(na.rm=TRUE, color="#00AFBB") +
  geom_text(aes(label=subject),hjust=1.5,vjust=1.5, color="#00AFBB", check_overlap=T)+
  scale_x_continuous(lim=c(-2.5, 2.5),breaks=seq(-3,3,1)) +
  scale_y_continuous(lim=c(-3.5, 3.5),breaks=seq(-3,3,1)) +
  geom_hline(yintercept=0, linetype="dashed") +
  geom_vline(xintercept=0, linetype="dashed") +
  labs(title="Individuals - PCA", x="Dim 1", y="Dim 2") +
  theme_minimal()+
  theme(plot.title=element_text(size=15),
        plot.subtitle=element_text(size=15, face="italic"),
        axis.title=element_text(size=15),
        axis.text=element_text(size=14),
        strip.background =element_rect(fill="white"),
        strip.text = element_text(size=14))+
  theme(legend.title = element_text(size=16),
        legend.text=element_text(size=14))
dimplot

## Merge loading and score plot = Biplot

# Biplot of factor loadings + ind factor scores
ggplot(rotScoreData, aes(x=Dim.1, y=Dim.2))+
  geom_point(na.rm=TRUE, color="#00AFBB") +
  geom_text(aes(label=subject),hjust=1.5,vjust=1.5, color="#00AFBB", check_overlap=T)+
  
  # Overlay loading plot (i.e. arrows)
  geom_segment(data=rotLoadingsData, mapping=aes(x=0, y=0, xend=Dim.1*4, yend=Dim.2*4), arrow=arrow(), size=0.5, color="black") +
  geom_text(data=rotLoadingsData, aes(x=Dim.1*4.5, y=Dim.2*4.5, label=variable), color="red",check_overlap=T, nudge_y = 0)+

  scale_x_continuous(lim=c(-3.5, 3.5),breaks=seq(-3,3,1)) +
  scale_y_continuous(lim=c(-4.5, 4.5),breaks=seq(-3,3,1)) +
  geom_hline(yintercept=0, linetype="dashed") +
  geom_vline(xintercept=0, linetype="dashed") +
  labs(title="Biplot - PCA", x="Dim 1", y="Dim 2") +
  theme_minimal()+
  theme(plot.title=element_text(size=15),
        plot.subtitle=element_text(size=15, face="italic"),
        axis.title=element_text(size=15),
        axis.text=element_text(size=14),
        strip.background =element_rect(fill="white"),
        strip.text = element_text(size=14))+
  theme(legend.title = element_text(size=16),
        legend.text=element_text(size=14))


```
The results of the rotated PCA with three components retained suggest that:
* Dim1 is a "race"-linked component, where WhAm is opposite to AsAm and EthCul aligns closely with AsAm in this data (there is also the case of Latina/Hispanic-interpreted individuals with high EthCul but low AsAm and WhAm, which is probably part of the lack of full alignment). We might think of this as the "what is your family background" dimension, where ethnic cultural activities seems to be tied to what your racial/ethnic background is regardless of where you grew up.
* Dim2 is a "culture"-linked component where ForAcc is opposite to AmCul and AmAcc tracks closely with AmCul. We might think of it as the "did you grow up in the US speaking American English" dimension, where your accent is tied to location but not necessarily tied to ethnic activities (though, I'm not sure exactly how participants interpreted the ethnic activities question for people who they perceived to be "foreign" ethnic rather than "American" ethnic).
* Dim3 is the "location"-linked component mapping most closely to FrCA but it doesn't align exactly, so I'm not sure whether it should be interpreted as Californian identity excluding factors associated with race and culture?

Based on the biplots, there are three rough visual clusters by Dim1 x Dim2 quadrants. 
* The first cluster is high/positive on Dim1 (Whiteness) and high/positive on Dim2 (Americanness), representing people who are interpreted as local White Americans who grew up in the US. Some of the White-interpreted people score more negative on Dim2, suggesting those seem less clearly American.
* The second cluster is low on Dim1 (=more Asianness) and high/positive on Dim2 (Americanness), seeming to represent people who are interpreted as local Asian Americans who grew up in the US (and namely speak English with an American accent).
* The third cluster is moderate-low on Dim1 (=more Asianness... but maybe lower on AsAm because see them as Asian but not American AND/OR lower on EthCul scoring due to foreign interpretation?) and low/negative on Dim2 (=more Foreignness... maybe linked to not growing up in the US or FOBbiness with a ForAcc). In actuality, there may not be a single cluster here, or even clear separation from the second cluster but more of a continuum (which would be expected). Still, this 'group' is interpreted as less likely to be labeled "Asian American" and less likely to have an "American Accent" (or more likely to have a "Foreign Accent"). There might be considere two sub-groups here as well: Those that are the most likely to have ForAcc (lowest point along Dim2) and less likely labelled "Asian American" vs. Those that are less likely to have ForAcc (closer to Dim2=0) and more likely labelled "Asian American".

##### Finalize Data
```{r}
# Merge PCA factor scores back to image number and raw scores
n1b_ratings_vars_pca <- n1b_scores_byImage %>%
  cbind(
    as_tibble(rotScores, rownames="Item"), . # alternatively rawScores
  ) %>%
select(Image_Cat, Image, 
       Dim1_White=Dim.1, Dim2_American=Dim.2, Dim3_NonCalifornian=Dim.3,
       FrCA, AsAm, WhAm, ForAcc, AmAcc, EthCul, AmCul
       )
n1b_ratings_vars_pca
```

```{r}
# Check how PCs map onto raw scores
# Which photos were selected as FrCA over 50% of the time
n1b_ratings_vars_pca %>% select(Image_Cat, Image, Dim3_NonCalifornian, FrCA) %>% arrange(-FrCA) %>% filter(FrCA>0.5) #%>% summarize(max_Dim3 = max(Dim3_NonCalifornian)) # Max Dim3 = 0.6065949
n1b_ratings_vars_pca %>% select(Image_Cat, Image, Dim3_NonCalifornian, FrCA) %>% arrange(Dim3_NonCalifornian)

# Which photos were selected as WhAm over 50% of the time
n1b_ratings_vars_pca %>% select(Image_Cat, Image, Dim1_White, AsAm, WhAm, EthCul, AmCul, FrCA) %>% arrange(-WhAm) %>% filter(WhAm>0.5) #%>% summarize(min_Dim1 = min(Dim1_White)) # Min Dim1 = 0.2245709	
# Which photos were selected as AsAm 
n1b_ratings_vars_pca %>% select(Image_Cat, Image, Dim1_White, AsAm, WhAm, EthCul, AmCul, FrCA) %>% arrange(-AsAm)

# Which photos were selected as AsAcc
n1b_ratings_vars_pca %>% select(Image_Cat, Image, Dim2_American, AmAcc, ForAcc, AmCul, EthCul, FrCA) %>% arrange(-AmAcc) %>%
  #filter(AmAcc>0.5) %>% 
  filter(Image_Cat=="AAW")
```

```{r}
# Summary stats of each PC/Dimension
n1b_ratings_vars_pca %>%
  summarize(
    Dim1_White_mean=mean(Dim1_White), Dim1_White_sd = sd(Dim1_White), 
    Dim1_White_min=min(Dim1_White), Dim1_White_max=max(Dim1_White), 
  )

n1b_ratings_vars_pca %>%
  summarize(
    Dim2_American_mean=mean(Dim2_American), Dim2_American_sd = sd(Dim2_American),
    Dim2_American_min=min(Dim2_American),  Dim2_American_max=max(Dim2_American)
  )

n1b_ratings_vars_pca %>%
  summarize(
    Dim3_NonCalifornian_mean=mean(Dim3_NonCalifornian), Dim3_NonCalifornian_sd = sd(Dim3_NonCalifornian),
    Dim3_NonCalifornian_min=min(Dim3_NonCalifornian),  Dim3_NonCalifornian_max=max(Dim3_NonCalifornian)
  )
```

##### Visualize Data
```{r}
# Check Raw score correlations
n1b_ratings_vars_pca %>% #filter(Image_Cat=="AAW") %>%
  ggplot(aes(y=EthCul, x=AsAm)) +  geom_point() + geom_smooth(method="lm") + theme_minimal()
n1b_ratings_vars_pca %>% #filter(Image_Cat=="AAW") %>%
  ggplot(aes(y=EthCul, x=WhAm)) +  geom_point() + geom_smooth(method="lm") + theme_minimal()
n1b_ratings_vars_pca %>% #filter(Image_Cat=="AAW") %>%
  ggplot(aes(y=EthCul, x=ForAcc)) +  geom_point() + geom_smooth(method="lm") + theme_minimal()
n1b_ratings_vars_pca %>% filter(Image_Cat=="AAW") %>%
  ggplot(aes(y=EthCul, x=AmAcc)) +  geom_point() + geom_smooth(method="lm") + theme_minimal()
```

```{r}
# Double check PCA correlations
n1b_ratings_vars_pca %>%
  ggplot() +
  # facet_wrap(~Image) +
  geom_point(aes(y=Dim3_NonCalifornian, x=FrCA)) +
  theme_minimal()

n1b_ratings_vars_pca %>%
  ggplot() +
  # facet_wrap(~Image) +
  geom_point(aes(y=Dim2_American, x=AmCul)) +
  geom_point(aes(y=Dim2_American, x=AmAcc), col="blue", alpha=0.7) +
  geom_point(aes(y=Dim2_American, x=ForAcc), col="red", alpha=0.7) +
  theme_minimal()

n1b_ratings_vars_pca %>%
  ggplot() +
  # facet_wrap(~Image) +
  geom_point(aes(y=Dim1_White, x=WhAm)) +
  geom_point(aes(y=Dim1_White, x=AsAm), col="blue", alpha=0.7) +
  geom_point(aes(y=Dim1_White, x=EthCul), col="red", alpha=0.7) +
  theme_minimal()
```

```{r}
# Dim3 not visualized 
n1b_ratings_vars_pca %>% #summarize(max=max(Dim3_NonCalifornian), min=min(Dim3_NonCalifornian))
  ggplot(aes(x=Dim1_White, y=Dim2_American, label=Image, color=Image_Cat)) +
  geom_point(alpha=0.7) +
  geom_text(alpha=0.7, nudge_x = 0.2, nudge_y = 0.2) +
  theme_minimal() 

# Dim3 visualized by alpha
n1b_ratings_vars_pca %>% #summarize(max=max(Dim3_NonCalifornian), min=min(Dim3_NonCalifornian))
  ggplot(aes(x=Dim1_White, y=Dim2_American, label=Image, alpha=-Dim3_NonCalifornian), color="black") +
  # facet_wrap(~Image) +
  geom_point() +
  geom_text(nudge_x = 0.2, nudge_y = 0.2) +
  # geom_point() +
  # geom_text(nudge_x = 0.2, nudge_y = 0.2) +
  theme_minimal() +
  # scale_color_manual(values = c("AAW-5" = "red")) +
  scale_alpha_continuous(range = c(-2.3, 2.3))

# Dim3 visualized by size
n1b_ratings_vars_pca %>% #summarize(max=max(Dim3_NonCalifornian), min=min(Dim3_NonCalifornian))
  ggplot(aes(x=Dim1_White, y=Dim2_American, label=Image, color=Image, size=-Dim3_NonCalifornian)) +
  # facet_wrap(~Image) +
  geom_point() +
  geom_text(nudge_x = 0.2, nudge_y = 0.2) +
  # geom_point() +
  # geom_text(nudge_x = 0.2, nudge_y = 0.2) +
  theme_minimal() +
  scale_color_manual(values = c("AAW-5" = "red"))
```


## Assess 
Now, for each persona profile, I want to see/select the top (e.g. ten) photos per combination by score. Then, go look at the photos and assess whether this all makes sense and I can use those photos for the next norming phase!

##### a) Mainstream White
```{r}
msWhite_images <- n1b_ratings_vars_pca %>%
  
  # Filters based on raw absolute/'objective' proportions (i.e., relative to external real world judgments and not just in dataset)
  filter(FrCA>0.5) %>%
  filter(WhAm>0.5) %>%
  # Filter for Dim1xDim2 quadrant — top right
  filter(Dim1_White>0) %>% # right
  filter(Dim2_American>0) %>% # top
  
  # Ranking
  mutate(Dim1_rank = rank(-Dim1_White, ties.method="min"), # low
         Dim2_rank = rank(-Dim2_American, ties.method="min"),
         Dim3_rank = rank(Dim3_NonCalifornian, ties.method="min"),
         .before=FrCA) %>%
  mutate(Overall_rank = (Dim1_rank+Dim2_rank)/2,  #Overall_rank = (Dim1_rank+Dim2_rank+Dim3_rank)/3, 
         .before=FrCA) %>%
  
  # Color
  mutate(Color="purple") %>%
  
  # Arrange by rank
  arrange(Dim2_rank)
  # arrange(Overall_rank)
msWhite_images

msWhite_images %>% filter(Dim3_NonCalifornian<0)
```
```{r}
n1b_ratings_vars_pca %>%
  ggplot(aes(x=Dim1_White, y=Dim2_American, label=Image)) +
  # facet_wrap(~Image) +
  geom_point() +
  # geom_text(nudge_x = 0.2, nudge_y = 0.2) +
  geom_point(data=msWhite_images, aes(color=Color, alpha=-Overall_rank)) +
  geom_text(data=msWhite_images, aes(color=Color, alpha=-Overall_rank), nudge_x = 0.2, nudge_y = 0.2) +
  theme_minimal() +
  scale_color_identity(aes(color=Color))
```

##### b) Mainstream Asian
```{r}
msAsian_images <- n1b_ratings_vars_pca %>%
  
  # Filters based on raw absolute/'objective' proportions (i.e., relative to external real world judgments and not just in dataset)
  filter(FrCA>0.5) %>%
  filter(AsAm>0.5) %>%
  # Filter for Dim1xDim2 quadrant — top left
  filter(Dim1_White<0) %>% # left
  filter(Dim2_American>0) %>% # top
  
  # Ranking
  mutate(Dim1_rank = rank(Dim1_White, ties.method="min"), # low
         Dim2_rank = rank(-Dim2_American, ties.method="min"),
         Dim3_rank = rank(Dim3_NonCalifornian, ties.method="min"),
         .before=FrCA) %>%
  mutate(Overall_rank = (Dim1_rank+Dim2_rank)/2,  #Overall_rank = (Dim1_rank+Dim2_rank+Dim3_rank)/3, 
         .before=FrCA) %>%
  
  # Color
  mutate(Color="orange") %>%
  
  # Arrange by rank
  arrange(Dim2_rank)
  # arrange(Overall_rank)
msAsian_images
```
```{r}
n1b_ratings_vars_pca %>%
  ggplot(aes(x=Dim1_White, y=Dim2_American, label=Image)) +
  # facet_wrap(~Image) +
  geom_point() +
  # geom_text(nudge_x = 0.2, nudge_y = 0.2) +
  geom_point(data=msAsian_images, aes(color=Color, alpha=-Dim2_rank)) +
  geom_text(data=msAsian_images, aes(color=Color, alpha=-Dim2_rank), nudge_x = 0.2, nudge_y = 0.2) +
  theme_minimal() +
  scale_color_identity(aes(color=Color))
```

##### c) Ethnic Asian
First dataframe matches the previous personae by screening for only those above 50% FrCA selections.
Also includes a separate dataframe with ALL potential options, not screening by FrCA at all, to see where other images fall as it's possible that FOB/ethnic personae may be less likely to be considered "from California" though it doesn't mean they can't be accepted as "Californian" just that they didn't grow up there (and different people may have interpreted that differently).

```{r}
ethAsian_images_all <- n1b_ratings_vars_pca %>%
  
  # Filters based on raw absolute/'objective' proportions (i.e., relative to external real world judgments and not just in dataset)
  filter(AsAm>0.5) %>%
  # Filter for Dim1xDim2 quadrant — bottom left
  filter(Dim1_White<0) %>% # left
  filter(Dim2_American<0) %>% # bottom
  
  # Ranking
  mutate(Dim1_rank = rank(Dim1_White, ties.method="min"), # low
         Dim2_rank = rank(Dim2_American, ties.method="min"),
         Dim3_rank = rank(Dim3_NonCalifornian, ties.method="min"),
         .before=FrCA) %>%
  mutate(Overall_rank = (Dim1_rank+Dim2_rank)/2,  #Overall_rank = (Dim1_rank+Dim2_rank+Dim3_rank)/3, 
         .before=FrCA) %>%
    
  # Color
  mutate(Color=ifelse(FrCA>=0.5, "red", "blue")) %>%
  # Arrange by rank
  
  # Filter by rank
  arrange(Dim2_rank)
  # arrange(Overall_rank)
ethAsian_images_all

ethAsian_images <- ethAsian_images_all %>%
  filter(FrCA>0.5)
ethAsian_images

# View only those rows in a certain range of FrCA proportions
ethAsian_images_all %>% filter(between(FrCA, 0.4, 0.5)) # between
ethAsian_images_all %>% filter(FrCA<0.4) # under 0.4

```

```{r}
n1b_ratings_vars_pca %>%
  ggplot(aes(x=Dim1_White, y=Dim2_American, label=Image)) +
  # facet_wrap(~Image) +
  geom_point() +
  # geom_text(nudge_x = 0.2, nudge_y = 0.2) +
  geom_point(data=ethAsian_images_all, aes(color=Color, alpha=-Dim3_rank)) +
  geom_text(data=ethAsian_images_all, aes(color=Color, alpha=-Dim3_rank), nudge_x = 0.2, nudge_y = 0.2) +
  theme_minimal() +
  scale_color_identity(aes(color=Color))
```

### Combine, Summarize, Visualize
```{r}
# Combine per-persona image data -- screened but not selected/excluded 
# Save to hardcopy in case want to revisit unselected options.
n1b_PCAscores_screenedImages <-
  msWhite_images %>%  mutate(Persona="msWhite", .before=Image_Cat) %>% # Select msWhite top 10
  full_join(
    msAsian_images %>% mutate(Persona="msAsian", .before=Image_Cat)   # Add msAsian top 10
  ) %>%
  full_join(
    ethAsian_images_all %>% mutate(Persona="ethAsian", .before=Image_Cat) # Add ethAsian top 10
  ) %>%
  mutate(Persona_Race = ifelse(Persona=="msWhite", "White", "Asian"),
         Persona_Orientation = ifelse(Persona=="ethAsian", "Ethnic", "Mainstream"),
         .after=Persona)
n1b_PCAscores_screenedImages
write_csv(n1b_PCAscores_screenedImages, file=file.path(pipeline, "out", "n1b_PCAscores_screenedImages.csv"))
```

```{r}
# Combine per-persona image data -- selected top 10 only (exclusions apply)
# Save to hardcopy to add to Google Sheets Visual Stimuli 
n1b_PCAscores_selectedImages <-
  # Select msWhite top 10
  msWhite_images %>%  mutate(Persona="msWhite", .before=Image_Cat) %>%
  filter(Dim3_NonCalifornian<0) %>% # Manual exclusion (see Experiments Project Home > Analysis Log)
  slice_min(Dim2_rank, n=10) %>%
  # Add msAsian top 10
  full_join(
    msAsian_images %>% mutate(Persona="msAsian", .before=Image_Cat) %>% 
    slice_min(Dim2_rank, n=10)
  ) %>%
  # Add ethAsian top 10
  full_join(
    ethAsian_images %>% mutate(Persona="ethAsian", .before=Image_Cat) %>%
    slice_min(Dim2_rank, n=7) %>%  # top 7 where FrCA>50
    filter(!(Image %in% c("AAW-10"))) # Manual exclusion (see Experiments Project Home > Analysis Log)
  )  %>%
  full_join(
    ethAsian_images_all %>% mutate(Persona="ethAsian", .before=Image_Cat) %>% 
    slice_min(Dim2_rank, n=5) %>% # supplement top 5 where FrCA>40
    filter(!(Image %in% c("AAW-54"))) # Manual exclusion (see Experiments Project Home > Analysis Log))
  ) %>%
  mutate(Persona_Race = ifelse(Persona=="msWhite", "White", "Asian"),
         Persona_Orientation = ifelse(Persona=="ethAsian", "Ethnic", "Mainstream"),
         .after=Persona)
n1b_PCAscores_selectedImages
write_csv(n1b_PCAscores_selectedImages, file=file.path(pipeline, "out", "n1b_PCAscores_selectedImages.csv"))

```


```{r}
# Calculate means per persona
personae_means <- n1b_PCAscores_selectedImages %>%
  group_by(Persona, Persona_Race, Persona_Orientation) %>% select(-Dim1_rank:-Overall_rank) %>%  summarize(across(where(is.numeric), mean))
personae_means

# Convert to long
personae_means_long <- personae_means %>% 
  pivot_longer(cols=Dim1_White:last_col(), names_to = "Score", values_to = "Value") %>%
  mutate(Score_Type = ifelse(Score %in% c("Dim1_White", "Dim2_American", "Dim3_NonCalifornian"), "PCA", "Raw"), .before=Score) %>%
  mutate(Score=fct_relevel(Score, "AsAm", "WhAm", "ForAcc", "AmAcc", "EthCul", "AmCul", "FrCA", ))

# Plot
personae_means_long %>%  filter(Score_Type=="PCA") %>%
  ggplot(aes(x=Persona, y=Value, fill=Score)) +
  theme_minimal() +
  geom_col(position="dodge", alpha=0.8)+
  scale_fill_brewer(palette = "Set2")

personae_means_long %>%  filter(Score_Type=="Raw") %>%
  ggplot(aes(x=Persona, y=Value, fill=Score)) +
  theme_minimal() +
  geom_col(position="dodge", alpha=0.8) +
  scale_fill_brewer(palette = "Paired")


```


## Visualize
Older code, before PCA was added. Review later for usefulness.
#### Pre-Scored Data
Showing a single selected image, raw values based on proportions.
```{r}
n1b_props_byImage %>%
  mutate(Descriptor=fct_relevel(Descriptor, "FrCA", "AsAm", "WhAm", "ForAcc", "AmAcc", "EthCul", "AmCul")) %>%

  filter(Image=="AAW-1" ) %>%
  ggplot(aes(y=prop_select, x=Descriptor)) +
  facet_wrap(~Image) +
  geom_col() +
  theme_minimal()
```
Showing all images, raw values based on proportions.
```{r}
n1b_props_byImage %>%
  filter(Image_Cat=="WAW" ) %>%
  ggplot(aes(y=prop_select, x=Descriptor)) +
  facet_wrap(~Image) +
  geom_col() +
  theme_minimal()

n1b_props_byImage %>%
  filter(Image_Cat=="AAW" ) %>%
  ggplot(aes(y=prop_select, x=Descriptor)) +
  facet_wrap(~Image) +
  geom_col() +
  theme_minimal()
```

#### Scored Data
##### Correlation Scatters
Check correlations in visualization between scores.
```{r}
colnames(n1b_scores_byImage)
```

Sanity Check: Relative vs. Raw Scores (Race)
```{r}
n1b_scores_byImage %>%
  ggplot(aes(y=AsAm, x=WhAm)) +
  # facet_wrap(~Image) +
  geom_point() +
  theme_minimal()

n1b_scores_byImage %>%
  ggplot(aes(y=RelAsAm, x=AsAm)) +
  # facet_wrap(~Image) +
  geom_point() +
  theme_minimal()

n1b_scores_byImage %>%
  ggplot(aes(y=RelAsAm, x=WhAm)) +
  # facet_wrap(~Image) +
  geom_point() +
  theme_minimal()
```
Rel vs. Raw Composite Scores
```{r}
n1b_scores_byImage %>%
  ggplot(aes(y=RelForEth_Score, x=Ethnic_Score)) +
  # facet_wrap(~Image) +
  geom_point() +
  theme_minimal()

n1b_scores_byImage %>%
  ggplot(aes(y=RelForEth_Score, x=Bicultural_Score)) +
  # facet_wrap(~Image) +
  geom_point() +
  theme_minimal()

n1b_scores_byImage %>%
  ggplot(aes(y=RelForEth_Score, x=Mainstream_Score)) +
  # facet_wrap(~Image) +
  geom_point() +
  theme_minimal()
```


##### By-Image Bars
By Individual Image: Visualize selection proportions by image for each of the descriptors.
```{r}
# Select an image to view by code
current_image = "AAW-1"

# Only Raw Scores
n1b_scores_byImage %>%
  pivot_longer(cols=3:last_col(), names_to = "Score", values_to = "Value") %>%
  filter(Score %in% c("FrCA", "AsAm", "WhAm", "ForAcc", "AmAcc", "EthCul", "AmCul")) %>%
  mutate(Score=fct_relevel(Score, 
                           "FrCA", "AsAm", "WhAm", "ForAcc", "AmAcc", "EthCul", "AmCul",
                           )) %>%

  filter(Image==current_image) %>%
  ggplot(aes(y=Value, x=Score)) +
  facet_wrap(~Image) +
  geom_col() +
  theme_minimal()

# Only Rel Scores
n1b_scores_byImage %>%
  pivot_longer(cols=3:last_col(), names_to = "Score", values_to = "Value") %>%
  filter(Score %in% c("RelAsAm", "RelForAcc", "RelEthCul", "RelForEth_Score")) %>%
  mutate(Score=fct_relevel(Score, 
                           "RelAsAm", "RelForAcc", "RelEthCul","RelForEth_Score"
                           )) %>%

  filter(Image==current_image) %>%
  ggplot(aes(y=Value, x=Score)) +
  facet_wrap(~Image) +
  geom_col() +
  theme_minimal()

# Only Composite Scores
n1b_scores_byImage %>%
  pivot_longer(cols=3:last_col(), names_to = "Score", values_to = "Value") %>%
  filter(Score %in% c("Ethnic_Score", "Bicultural_Score", "Mainstream_Score")) %>%
  mutate(Score=fct_relevel(Score, 
                           "Ethnic_Score", "Bicultural_Score", "Mainstream_Score",
                           )) %>%

  filter(Image==current_image) %>%
  ggplot(aes(y=Value, x=Score)) +
  facet_wrap(~Image) +
  geom_col() +
  theme_minimal()
```



# .
# Graveyard
Code snippets or temporary code that you don't need but don't want to delete just yet

```{r}
#SS Loadings
# with factor score matrix, by squaring and summing, get eigenvalues
as_tibble(eigenvectors, rownames="Score")%>% mutate(across(where(is.numeric), ~.^2)) %>% summarize(across(where(is.numeric), sum)) %>%
  pivot_longer(everything(), names_to = "comp", values_to = "Squared") %>%
  mutate(PercentVariance = Squared/7) %>%
  summarize(across(where(is.numeric), sum))
# with factor loadings, by squaring and summing, get 1 for all.
as_tibble(rawLoadings, rownames="Score") %>% mutate(across(where(is.numeric), ~.^2)) %>% summarize(across(where(is.numeric), sum)) %>%
  #mutate(TotalSum=rowSums(.)) %>%
  #mutate(TotalVariance=TotalSum/7)
  pivot_longer(everything(), names_to = "comp", values_to = "Squared") %>%
  mutate(PercentVariance = Squared/7) %>%
  summarize(across(where(is.numeric), sum))

```

```{r}
# Try rotation on the eigenvectors anyway (even though not typically done), to see if I can get reasonable looking SS loadings and PercentVariance. Yes, however, this result is different from rotating on the loadings.
rotLoadings <- Varimax(eigenvectors, normalize=T)$loadings
as_tibble(rotLoadings, rownames="Score") 

rotMatrixL <- t(eigenvectors) %*% rotLoadings
as_tibble(rotMatrixL, rownames="Dimensions")

zScores <- scale(rawScores)
rotScores <- zScores %*% rotMatrixL
as_tibble(rotScores, rownames="Item")

as_tibble(rotLoadings, rownames="Score")%>% mutate(across(where(is.numeric), ~.^2)) %>% summarize(across(where(is.numeric), sum)) %>%
  pivot_longer(everything(), names_to = "comp", values_to = "Squared") %>%
  mutate(PercentVariance = Squared/7) #%>%
  #summarize(across(where(is.numeric), sum)) #total% same as original
```
```{r}
n1b_scores_byImage %>%
  select(Image_Cat, Image, 
         FrCA,
         RelAsAm, WhAm, #AsAm, 
         RelForEth_Score,
         Mainstream_Score, #Ethnic_Score,
         RelForAcc, RelEthCul,
         AmAcc, AmCul #ForAcc, EthCul
         ) %>%
  filter(FrCA>0.5) %>% # Keep Plausibly Californian
  filter(RelAsAm<0 & WhAm>0.5) %>% # Keep Plausibly White American (and more WhAm than AsAm)
  
  # Get ranks
  mutate(RelForEth_rank = rank(RelForEth_Score, ties.method="min"), # low
         Mainstream_rank = rank(-Mainstream_Score, ties.method="min"),    # high
         
         RelAsAm_rank = rank(RelAsAm, ties.method="min"),           # low 
         RelForAcc_rank = rank(RelForAcc, ties.method="min"),       # low 
         RelEthCul_rank = rank(RelEthCul, ties.method="min"),       # low 
         
         WhAm_rank = rank(-WhAm, ties.method="min"),                # high
         AmAcc_rank = rank(-AmAcc, ties.method="min"),              # high
         AmCul_rank = rank(-AmCul, ties.method="min"),              # high
         .after=Mainstream_Score) %>%
  mutate(Overall_rank = ((RelForEth_rank+Mainstream_rank)/2), 
         .after=Mainstream_Score) %>%
  
  # Show top values
  arrange(Overall_rank) # order by X
  # slice_max(order_by=Mainstream_Score, n=10) # only show top X
```


##### b) Ethnic Asian
```{r}
n1b_scores_byImage %>%
  select(Image_Cat, Image, 
         FrCA,
         RelAsAm, AsAm, #WhAm, 
         RelForEth_Score,
         Ethnic_Score, #Mainstream_Score,
         RelForAcc, RelEthCul,
         ForAcc, EthCul #AmAcc, AmCul
         ) %>%
  filter(FrCA>0.5) %>% # Keep Plausibly Californian
  filter(RelAsAm>0 & AsAm>0.5) %>% # Keep Plausibly Asian American (and more AsAm than WhAm)
  
  # Get ranks
  mutate(RelForEth_rank = rank(-RelForEth_Score, ties.method="min"), # high
         Ethnic_rank = rank(-Ethnic_Score, ties.method="min"),   # high
         
         RelAsAm_rank = rank(-RelAsAm, ties.method="min"),           # high
         RelForAcc_rank = rank(-RelForAcc, ties.method="min"),       # high
         RelEthCul_rank = rank(-RelEthCul, ties.method="min"),       # high
         
         AsAm_rank = rank(-AsAm, ties.method="min"),                 # high
         ForAcc_rank = rank(-ForAcc, ties.method="min"),             # high
         EthCul_rank = rank(-EthCul, ties.method="min"),             # high
         .after=Ethnic_Score) %>%
  mutate(Overall_rank = ((RelForEth_rank+Ethnic_rank)/2), 
         .after=Ethnic_Score) %>%
  
  # Show top values
  arrange(Overall_rank) # order by X
  # slice_max(order_by=Mainstream_Score, n=10) # only show top X
```

##### c) Mainstream Asian
```{r}
n1b_scores_byImage %>%
  select(Image_Cat, Image, 
         FrCA,
         RelAsAm, AsAm, #WhAm, 
         RelForEth_Score,
         Bicultural_Score, #Ethnic_Score, #Mainstream_Score,
         RelForAcc, RelEthCul,
         ForAcc, EthCul #AmAcc, AmCul
         ) %>%
  filter(FrCA>0.5) %>% # Keep Plausibly Californian
  filter(RelAsAm>0 & AsAm>0.5) %>% # Keep Plausibly Asian American (and more AsAm than WhAm)
  
  # Get ranks
  mutate(RelForEth_rank = rank(RelForEth_Score, ties.method="min"),  # low <-- consider rank of absolute value from low (near 0)
         Bicultural_rank = rank(-Bicultural_Score, ties.method="min"),     # high
         
         RelAsAm_rank = rank(-RelAsAm, ties.method="min"),           # high
         RelForAcc_rank = rank(RelForAcc, ties.method="min"),        # low  (<-- consider rank of absolute value from low (near 0))
         RelEthCul_rank = rank(RelEthCul, ties.method="min"),        # low <-- consider rank of absolute value from low (near 0)
         
         AsAm_rank = rank(-AsAm, ties.method="min"),                 # high
         ForAcc_rank = rank(ForAcc, ties.method="min"),              # low (<-- consider rank of absolute value from low (near 0))
         EthCul_rank = rank(EthCul, ties.method="min"),              # low <-- consider rank of absolute value from low (near 0)
         .after=Bicultural_Score) %>%
  mutate(Overall_rank = ((RelForEth_rank+Bicultural_rank)/2), 
         .after=Bicultural_Score) %>%
  
  # Show top values
  arrange(Overall_rank) # order by X
  # slice_max(order_by=Mainstream_Score, n=10) # only show top X
```
